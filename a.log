>> TRAIN ALL (word2vec) <<
> training <main> ...
>> MAIN-category
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  loc.txt (835, 9600) (835,) 835
TEST ::  loc.txt (81, 9600) (81,) 81
TRAIN ::  enty.txt (1250, 9600) (1250,) 1250
TEST ::  enty.txt (94, 9600) (94,) 94
TRAIN ::  hum.txt (1223, 9600) (1223,) 1223
TEST ::  hum.txt (65, 9600) (65,) 65
TRAIN ::  num.txt (896, 9600) (896,) 896
TEST ::  num.txt (113, 9600) (113,) 113
TRAIN ::  abbr.txt (86, 9600) (86,) 86
TEST ::  abbr.txt (9, 9600) (9,) 9
TRAIN ::  desc.txt (1162, 9600) (1162,) 1162
TEST ::  desc.txt (138, 9600) (138,) 138
x_train: (5452, 9600)  - y_train: (5452,) - train_questions: 5452
x_test: (500, 9600)  - y_test: (500,) - test_questions: 500
x_train: (5452, 32, 300, 1)  - y_train: (5452, 6) - train_questions: 5452
x_test: (500, 32, 300, 1)  - y_test: (500, 6) - test_questions: 500
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 6)            390         dropout_2[0][0]                  
==================================================================================================
Total params: 2,366,774
Trainable params: 2,366,774
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 5452 samples, validate on 500 samples
Epoch 1/200

  50/5452 [..............................] - ETA: 3:34 - loss: 1.7991 - acc: 0.1600
 150/5452 [..............................] - ETA: 1:13 - loss: 1.7278 - acc: 0.2333
 250/5452 [>.............................] - ETA: 44s - loss: 1.6868 - acc: 0.2560 
 350/5452 [>.............................] - ETA: 32s - loss: 1.6674 - acc: 0.2600
 450/5452 [=>............................] - ETA: 25s - loss: 1.6328 - acc: 0.2800
 550/5452 [==>...........................] - ETA: 21s - loss: 1.6029 - acc: 0.2964
 650/5452 [==>...........................] - ETA: 17s - loss: 1.5582 - acc: 0.3262
 750/5452 [===>..........................] - ETA: 15s - loss: 1.5272 - acc: 0.3413
 850/5452 [===>..........................] - ETA: 13s - loss: 1.4831 - acc: 0.3659
 950/5452 [====>.........................] - ETA: 12s - loss: 1.4260 - acc: 0.4021
1050/5452 [====>.........................] - ETA: 11s - loss: 1.3899 - acc: 0.4248
1150/5452 [=====>........................] - ETA: 10s - loss: 1.3588 - acc: 0.4409
1250/5452 [=====>........................] - ETA: 9s - loss: 1.3292 - acc: 0.4568 
1350/5452 [======>.......................] - ETA: 8s - loss: 1.3004 - acc: 0.4726
1450/5452 [======>.......................] - ETA: 8s - loss: 1.2681 - acc: 0.4903
1550/5452 [=======>......................] - ETA: 7s - loss: 1.2376 - acc: 0.5026
1650/5452 [========>.....................] - ETA: 7s - loss: 1.2168 - acc: 0.5158
1750/5452 [========>.....................] - ETA: 6s - loss: 1.1848 - acc: 0.5309
1850/5452 [=========>....................] - ETA: 6s - loss: 1.1653 - acc: 0.5400
1950/5452 [=========>....................] - ETA: 5s - loss: 1.1482 - acc: 0.5467
2050/5452 [==========>...................] - ETA: 5s - loss: 1.1332 - acc: 0.5556
2150/5452 [==========>...................] - ETA: 5s - loss: 1.1111 - acc: 0.5665
2250/5452 [===========>..................] - ETA: 4s - loss: 1.0905 - acc: 0.5769
2350/5452 [===========>..................] - ETA: 4s - loss: 1.0729 - acc: 0.5843
2450/5452 [============>.................] - ETA: 4s - loss: 1.0576 - acc: 0.5906
2550/5452 [=============>................] - ETA: 4s - loss: 1.0462 - acc: 0.5957
2650/5452 [=============>................] - ETA: 3s - loss: 1.0366 - acc: 0.5985
2750/5452 [==============>...............] - ETA: 3s - loss: 1.0212 - acc: 0.6047
2850/5452 [==============>...............] - ETA: 3s - loss: 1.0114 - acc: 0.6088
2950/5452 [===============>..............] - ETA: 3s - loss: 0.9991 - acc: 0.6139
3050/5452 [===============>..............] - ETA: 3s - loss: 0.9887 - acc: 0.6187
3150/5452 [================>.............] - ETA: 2s - loss: 0.9779 - acc: 0.6222
3250/5452 [================>.............] - ETA: 2s - loss: 0.9706 - acc: 0.6268
3350/5452 [=================>............] - ETA: 2s - loss: 0.9570 - acc: 0.6334
3450/5452 [=================>............] - ETA: 2s - loss: 0.9432 - acc: 0.6394
3550/5452 [==================>...........] - ETA: 2s - loss: 0.9342 - acc: 0.6434
3650/5452 [===================>..........] - ETA: 2s - loss: 0.9207 - acc: 0.6490
3750/5452 [===================>..........] - ETA: 1s - loss: 0.9095 - acc: 0.6547
3850/5452 [====================>.........] - ETA: 1s - loss: 0.9012 - acc: 0.6595
3950/5452 [====================>.........] - ETA: 1s - loss: 0.8945 - acc: 0.6625
4050/5452 [=====================>........] - ETA: 1s - loss: 0.8856 - acc: 0.6667
4150/5452 [=====================>........] - ETA: 1s - loss: 0.8743 - acc: 0.6713
4250/5452 [======================>.......] - ETA: 1s - loss: 0.8655 - acc: 0.6753
4350/5452 [======================>.......] - ETA: 1s - loss: 0.8579 - acc: 0.6786
4450/5452 [=======================>......] - ETA: 1s - loss: 0.8489 - acc: 0.6829
4550/5452 [========================>.....] - ETA: 0s - loss: 0.8398 - acc: 0.6862
4650/5452 [========================>.....] - ETA: 0s - loss: 0.8302 - acc: 0.6908
4750/5452 [=========================>....] - ETA: 0s - loss: 0.8235 - acc: 0.6943
4850/5452 [=========================>....] - ETA: 0s - loss: 0.8185 - acc: 0.6973
4950/5452 [==========================>...] - ETA: 0s - loss: 0.8130 - acc: 0.7000
5050/5452 [==========================>...] - ETA: 0s - loss: 0.8046 - acc: 0.7038
5150/5452 [===========================>..] - ETA: 0s - loss: 0.7999 - acc: 0.7064
5250/5452 [===========================>..] - ETA: 0s - loss: 0.7939 - acc: 0.7084
5350/5452 [============================>.] - ETA: 0s - loss: 0.7876 - acc: 0.7107
5450/5452 [============================>.] - ETA: 0s - loss: 0.7800 - acc: 0.7134
5452/5452 [==============================] - 6s 1ms/step - loss: 0.7802 - acc: 0.7133 - val_loss: 0.2877 - val_acc: 0.9100

Epoch 00001: val_acc improved from -inf to 0.91000, saving model to word2vec_main_model.h5
Epoch 2/200

  50/5452 [..............................] - ETA: 3s - loss: 0.2887 - acc: 0.9000
 150/5452 [..............................] - ETA: 3s - loss: 0.3799 - acc: 0.8800
 250/5452 [>.............................] - ETA: 3s - loss: 0.3971 - acc: 0.8680
 350/5452 [>.............................] - ETA: 3s - loss: 0.4066 - acc: 0.8686
 450/5452 [=>............................] - ETA: 3s - loss: 0.3978 - acc: 0.8644
 550/5452 [==>...........................] - ETA: 3s - loss: 0.4027 - acc: 0.8564
 650/5452 [==>...........................] - ETA: 2s - loss: 0.4017 - acc: 0.8615
 750/5452 [===>..........................] - ETA: 2s - loss: 0.3865 - acc: 0.8693
 850/5452 [===>..........................] - ETA: 2s - loss: 0.3659 - acc: 0.8788
 950/5452 [====>.........................] - ETA: 2s - loss: 0.3671 - acc: 0.8789
1050/5452 [====>.........................] - ETA: 2s - loss: 0.3744 - acc: 0.8790
1150/5452 [=====>........................] - ETA: 2s - loss: 0.3664 - acc: 0.8835
1250/5452 [=====>........................] - ETA: 2s - loss: 0.3662 - acc: 0.8824
1350/5452 [======>.......................] - ETA: 2s - loss: 0.3656 - acc: 0.8815
1450/5452 [======>.......................] - ETA: 2s - loss: 0.3614 - acc: 0.8821
1550/5452 [=======>......................] - ETA: 2s - loss: 0.3534 - acc: 0.8845
1650/5452 [========>.....................] - ETA: 2s - loss: 0.3472 - acc: 0.8855
1750/5452 [========>.....................] - ETA: 2s - loss: 0.3458 - acc: 0.8851
1850/5452 [=========>....................] - ETA: 2s - loss: 0.3416 - acc: 0.8870
1950/5452 [=========>....................] - ETA: 2s - loss: 0.3374 - acc: 0.8892
2050/5452 [==========>...................] - ETA: 2s - loss: 0.3372 - acc: 0.8888
2150/5452 [==========>...................] - ETA: 2s - loss: 0.3397 - acc: 0.8893
2250/5452 [===========>..................] - ETA: 1s - loss: 0.3428 - acc: 0.8876
2350/5452 [===========>..................] - ETA: 1s - loss: 0.3359 - acc: 0.8906
2450/5452 [============>.................] - ETA: 1s - loss: 0.3390 - acc: 0.8886
2550/5452 [=============>................] - ETA: 1s - loss: 0.3343 - acc: 0.8906
2650/5452 [=============>................] - ETA: 1s - loss: 0.3281 - acc: 0.8928
2750/5452 [==============>...............] - ETA: 1s - loss: 0.3271 - acc: 0.8931
2850/5452 [==============>...............] - ETA: 1s - loss: 0.3219 - acc: 0.8940
2950/5452 [===============>..............] - ETA: 1s - loss: 0.3220 - acc: 0.8942
3050/5452 [===============>..............] - ETA: 1s - loss: 0.3203 - acc: 0.8957
3150/5452 [================>.............] - ETA: 1s - loss: 0.3237 - acc: 0.8946
3250/5452 [================>.............] - ETA: 1s - loss: 0.3187 - acc: 0.8957
3350/5452 [=================>............] - ETA: 1s - loss: 0.3212 - acc: 0.8949
3450/5452 [=================>............] - ETA: 1s - loss: 0.3211 - acc: 0.8942
3550/5452 [==================>...........] - ETA: 1s - loss: 0.3210 - acc: 0.8938
3650/5452 [===================>..........] - ETA: 1s - loss: 0.3179 - acc: 0.8945
3750/5452 [===================>..........] - ETA: 1s - loss: 0.3157 - acc: 0.8960
3850/5452 [====================>.........] - ETA: 0s - loss: 0.3141 - acc: 0.8971
3950/5452 [====================>.........] - ETA: 0s - loss: 0.3138 - acc: 0.8972
4050/5452 [=====================>........] - ETA: 0s - loss: 0.3152 - acc: 0.8965
4150/5452 [=====================>........] - ETA: 0s - loss: 0.3138 - acc: 0.8971
4250/5452 [======================>.......] - ETA: 0s - loss: 0.3138 - acc: 0.8974
4350/5452 [======================>.......] - ETA: 0s - loss: 0.3135 - acc: 0.8975
4450/5452 [=======================>......] - ETA: 0s - loss: 0.3145 - acc: 0.8971
4550/5452 [========================>.....] - ETA: 0s - loss: 0.3120 - acc: 0.8976
4650/5452 [========================>.....] - ETA: 0s - loss: 0.3118 - acc: 0.8978
4750/5452 [=========================>....] - ETA: 0s - loss: 0.3097 - acc: 0.8985
4850/5452 [=========================>....] - ETA: 0s - loss: 0.3074 - acc: 0.8998
4950/5452 [==========================>...] - ETA: 0s - loss: 0.3077 - acc: 0.8996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.3069 - acc: 0.9004
5150/5452 [===========================>..] - ETA: 0s - loss: 0.3065 - acc: 0.9014
5250/5452 [===========================>..] - ETA: 0s - loss: 0.3066 - acc: 0.9011
5350/5452 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9007
5450/5452 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.9007
5452/5452 [==============================] - 3s 628us/step - loss: 0.3073 - acc: 0.9008 - val_loss: 0.2779 - val_acc: 0.9080

Epoch 00002: val_acc did not improve from 0.91000
Epoch 3/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0989 - acc: 0.9600
 150/5452 [..............................] - ETA: 3s - loss: 0.1027 - acc: 0.9800
 250/5452 [>.............................] - ETA: 3s - loss: 0.1507 - acc: 0.9640
 350/5452 [>.............................] - ETA: 3s - loss: 0.1690 - acc: 0.9600
 450/5452 [=>............................] - ETA: 3s - loss: 0.1676 - acc: 0.9600
 550/5452 [==>...........................] - ETA: 2s - loss: 0.1556 - acc: 0.9636
 650/5452 [==>...........................] - ETA: 2s - loss: 0.1555 - acc: 0.9615
 750/5452 [===>..........................] - ETA: 2s - loss: 0.1549 - acc: 0.9600
 850/5452 [===>..........................] - ETA: 2s - loss: 0.1537 - acc: 0.9588
 950/5452 [====>.........................] - ETA: 2s - loss: 0.1561 - acc: 0.9579
1050/5452 [====>.........................] - ETA: 2s - loss: 0.1500 - acc: 0.9590
1150/5452 [=====>........................] - ETA: 2s - loss: 0.1509 - acc: 0.9557
1250/5452 [=====>........................] - ETA: 2s - loss: 0.1478 - acc: 0.9576
1350/5452 [======>.......................] - ETA: 2s - loss: 0.1441 - acc: 0.9578
1450/5452 [======>.......................] - ETA: 2s - loss: 0.1422 - acc: 0.9593
1550/5452 [=======>......................] - ETA: 2s - loss: 0.1406 - acc: 0.9606
1650/5452 [========>.....................] - ETA: 2s - loss: 0.1391 - acc: 0.9606
1750/5452 [========>.....................] - ETA: 2s - loss: 0.1423 - acc: 0.9606
1850/5452 [=========>....................] - ETA: 2s - loss: 0.1375 - acc: 0.9627
1950/5452 [=========>....................] - ETA: 2s - loss: 0.1398 - acc: 0.9621
2050/5452 [==========>...................] - ETA: 2s - loss: 0.1382 - acc: 0.9624
2150/5452 [==========>...................] - ETA: 2s - loss: 0.1386 - acc: 0.9628
2250/5452 [===========>..................] - ETA: 1s - loss: 0.1382 - acc: 0.9622
2350/5452 [===========>..................] - ETA: 1s - loss: 0.1372 - acc: 0.9626
2450/5452 [============>.................] - ETA: 1s - loss: 0.1342 - acc: 0.9641
2550/5452 [=============>................] - ETA: 1s - loss: 0.1310 - acc: 0.9647
2650/5452 [=============>................] - ETA: 1s - loss: 0.1312 - acc: 0.9645
2750/5452 [==============>...............] - ETA: 1s - loss: 0.1298 - acc: 0.9651
2850/5452 [==============>...............] - ETA: 1s - loss: 0.1297 - acc: 0.9656
2950/5452 [===============>..............] - ETA: 1s - loss: 0.1276 - acc: 0.9661
3050/5452 [===============>..............] - ETA: 1s - loss: 0.1246 - acc: 0.9669
3150/5452 [================>.............] - ETA: 1s - loss: 0.1244 - acc: 0.9670
3250/5452 [================>.............] - ETA: 1s - loss: 0.1221 - acc: 0.9677
3350/5452 [=================>............] - ETA: 1s - loss: 0.1234 - acc: 0.9675
3450/5452 [=================>............] - ETA: 1s - loss: 0.1214 - acc: 0.9678
3550/5452 [==================>...........] - ETA: 1s - loss: 0.1203 - acc: 0.9679
3650/5452 [===================>..........] - ETA: 1s - loss: 0.1187 - acc: 0.9685
3750/5452 [===================>..........] - ETA: 1s - loss: 0.1198 - acc: 0.9675
3850/5452 [====================>.........] - ETA: 0s - loss: 0.1186 - acc: 0.9675
3950/5452 [====================>.........] - ETA: 0s - loss: 0.1185 - acc: 0.9676
4050/5452 [=====================>........] - ETA: 0s - loss: 0.1179 - acc: 0.9679
4150/5452 [=====================>........] - ETA: 0s - loss: 0.1199 - acc: 0.9675
4250/5452 [======================>.......] - ETA: 0s - loss: 0.1190 - acc: 0.9678
4350/5452 [======================>.......] - ETA: 0s - loss: 0.1198 - acc: 0.9678
4450/5452 [=======================>......] - ETA: 0s - loss: 0.1203 - acc: 0.9681
4550/5452 [========================>.....] - ETA: 0s - loss: 0.1216 - acc: 0.9673
4650/5452 [========================>.....] - ETA: 0s - loss: 0.1242 - acc: 0.9660
4750/5452 [=========================>....] - ETA: 0s - loss: 0.1234 - acc: 0.9661
4850/5452 [=========================>....] - ETA: 0s - loss: 0.1228 - acc: 0.9666
4950/5452 [==========================>...] - ETA: 0s - loss: 0.1216 - acc: 0.9669
5050/5452 [==========================>...] - ETA: 0s - loss: 0.1217 - acc: 0.9663
5150/5452 [===========================>..] - ETA: 0s - loss: 0.1215 - acc: 0.9662
5250/5452 [===========================>..] - ETA: 0s - loss: 0.1211 - acc: 0.9663
5350/5452 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9658
5450/5452 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9653
5452/5452 [==============================] - 3s 628us/step - loss: 0.1231 - acc: 0.9653 - val_loss: 0.2816 - val_acc: 0.9140

Epoch 00003: val_acc improved from 0.91000 to 0.91400, saving model to word2vec_main_model.h5
Epoch 4/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0464 - acc: 0.9800
 150/5452 [..............................] - ETA: 3s - loss: 0.0472 - acc: 0.9867
 250/5452 [>.............................] - ETA: 3s - loss: 0.0561 - acc: 0.9880
 350/5452 [>.............................] - ETA: 3s - loss: 0.0725 - acc: 0.9829
 450/5452 [=>............................] - ETA: 3s - loss: 0.0752 - acc: 0.9844
 550/5452 [==>...........................] - ETA: 3s - loss: 0.0731 - acc: 0.9818
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0725 - acc: 0.9831
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0695 - acc: 0.9827
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0661 - acc: 0.9847
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0774 - acc: 0.9832
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0763 - acc: 0.9819
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0768 - acc: 0.9817
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0896 - acc: 0.9776
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0874 - acc: 0.9778
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0861 - acc: 0.9779
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0836 - acc: 0.9787
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0824 - acc: 0.9788
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0800 - acc: 0.9794
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0807 - acc: 0.9795
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0784 - acc: 0.9800
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0760 - acc: 0.9810
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0788 - acc: 0.9795
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0804 - acc: 0.9787
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0796 - acc: 0.9787
2450/5452 [============>.................] - ETA: 1s - loss: 0.0802 - acc: 0.9788
2550/5452 [=============>................] - ETA: 1s - loss: 0.0792 - acc: 0.9796
2650/5452 [=============>................] - ETA: 1s - loss: 0.0816 - acc: 0.9785
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0803 - acc: 0.9789
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0792 - acc: 0.9793
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0777 - acc: 0.9800
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0766 - acc: 0.9803
3150/5452 [================>.............] - ETA: 1s - loss: 0.0754 - acc: 0.9810
3250/5452 [================>.............] - ETA: 1s - loss: 0.0745 - acc: 0.9809
3350/5452 [=================>............] - ETA: 1s - loss: 0.0752 - acc: 0.9806
3450/5452 [=================>............] - ETA: 1s - loss: 0.0741 - acc: 0.9809
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0739 - acc: 0.9806
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0740 - acc: 0.9805
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0730 - acc: 0.9805
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0728 - acc: 0.9803
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0721 - acc: 0.9803
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0718 - acc: 0.9802
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0726 - acc: 0.9800
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0723 - acc: 0.9802
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0711 - acc: 0.9807
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0709 - acc: 0.9807
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0705 - acc: 0.9809
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0695 - acc: 0.9813
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0688 - acc: 0.9815
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0681 - acc: 0.9816
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0675 - acc: 0.9818
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0677 - acc: 0.9816
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0680 - acc: 0.9814
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9815
5350/5452 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9819
5450/5452 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9820
5452/5452 [==============================] - 3s 630us/step - loss: 0.0675 - acc: 0.9820 - val_loss: 0.2996 - val_acc: 0.9120

Epoch 00004: val_acc did not improve from 0.91400
Epoch 5/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0780 - acc: 0.9800
 150/5452 [..............................] - ETA: 3s - loss: 0.0401 - acc: 0.9933
 250/5452 [>.............................] - ETA: 3s - loss: 0.0340 - acc: 0.9960
 350/5452 [>.............................] - ETA: 3s - loss: 0.0334 - acc: 0.9943
 450/5452 [=>............................] - ETA: 3s - loss: 0.0293 - acc: 0.9956
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0313 - acc: 0.9945
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0282 - acc: 0.9954
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0308 - acc: 0.9947
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0341 - acc: 0.9941
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0376 - acc: 0.9937
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0366 - acc: 0.9933
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0371 - acc: 0.9930
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0352 - acc: 0.9936
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0339 - acc: 0.9933
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0327 - acc: 0.9938
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0320 - acc: 0.9935
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0311 - acc: 0.9939
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0306 - acc: 0.9937
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0298 - acc: 0.9941
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0294 - acc: 0.9944
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0285 - acc: 0.9946
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0288 - acc: 0.9944
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0286 - acc: 0.9942
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0283 - acc: 0.9945
2450/5452 [============>.................] - ETA: 1s - loss: 0.0300 - acc: 0.9943
2550/5452 [=============>................] - ETA: 1s - loss: 0.0299 - acc: 0.9945
2650/5452 [=============>................] - ETA: 1s - loss: 0.0294 - acc: 0.9947
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0286 - acc: 0.9949
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0287 - acc: 0.9947
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0294 - acc: 0.9946
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0304 - acc: 0.9944
3150/5452 [================>.............] - ETA: 1s - loss: 0.0297 - acc: 0.9946
3250/5452 [================>.............] - ETA: 1s - loss: 0.0294 - acc: 0.9945
3350/5452 [=================>............] - ETA: 1s - loss: 0.0291 - acc: 0.9943
3450/5452 [=================>............] - ETA: 1s - loss: 0.0288 - acc: 0.9945
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0284 - acc: 0.9946
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0284 - acc: 0.9945
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0280 - acc: 0.9947
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0277 - acc: 0.9948
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0273 - acc: 0.9949
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0269 - acc: 0.9951
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0268 - acc: 0.9949
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0271 - acc: 0.9946
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0267 - acc: 0.9947
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0264 - acc: 0.9948
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0261 - acc: 0.9949
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0263 - acc: 0.9948
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0260 - acc: 0.9949
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0260 - acc: 0.9948
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0259 - acc: 0.9947
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0257 - acc: 0.9949
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0272 - acc: 0.9948
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0269 - acc: 0.9949
5350/5452 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9948
5450/5452 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9949
5452/5452 [==============================] - 3s 630us/step - loss: 0.0270 - acc: 0.9949 - val_loss: 0.3879 - val_acc: 0.8980

Epoch 00005: val_acc did not improve from 0.91400
Epoch 6/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0074 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0186 - acc: 0.9933
 250/5452 [>.............................] - ETA: 3s - loss: 0.0167 - acc: 0.9960
 350/5452 [>.............................] - ETA: 3s - loss: 0.0375 - acc: 0.9943
 450/5452 [=>............................] - ETA: 3s - loss: 0.0312 - acc: 0.9956
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0269 - acc: 0.9964
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0314 - acc: 0.9954
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0291 - acc: 0.9960
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0269 - acc: 0.9965
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0277 - acc: 0.9958
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0265 - acc: 0.9952
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0254 - acc: 0.9957
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0256 - acc: 0.9952
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0245 - acc: 0.9956
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0250 - acc: 0.9952
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0245 - acc: 0.9955
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0236 - acc: 0.9958
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0265 - acc: 0.9943
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0261 - acc: 0.9941
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0256 - acc: 0.9944
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0248 - acc: 0.9946
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0251 - acc: 0.9944
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0246 - acc: 0.9942
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0241 - acc: 0.9945
2450/5452 [============>.................] - ETA: 1s - loss: 0.0236 - acc: 0.9947
2550/5452 [=============>................] - ETA: 1s - loss: 0.0230 - acc: 0.9949
2650/5452 [=============>................] - ETA: 1s - loss: 0.0238 - acc: 0.9947
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0231 - acc: 0.9949
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0230 - acc: 0.9951
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0227 - acc: 0.9953
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0225 - acc: 0.9954
3150/5452 [================>.............] - ETA: 1s - loss: 0.0220 - acc: 0.9956
3250/5452 [================>.............] - ETA: 1s - loss: 0.0216 - acc: 0.9957
3350/5452 [=================>............] - ETA: 1s - loss: 0.0216 - acc: 0.9958
3450/5452 [=================>............] - ETA: 1s - loss: 0.0221 - acc: 0.9957
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0222 - acc: 0.9955
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0229 - acc: 0.9951
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0226 - acc: 0.9952
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0224 - acc: 0.9953
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0236 - acc: 0.9952
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0234 - acc: 0.9953
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0236 - acc: 0.9949
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0233 - acc: 0.9951
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0230 - acc: 0.9952
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0230 - acc: 0.9951
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0231 - acc: 0.9949
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0229 - acc: 0.9951
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0228 - acc: 0.9952
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0225 - acc: 0.9953
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0236 - acc: 0.9952
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0234 - acc: 0.9952
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0232 - acc: 0.9953
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0229 - acc: 0.9954
5350/5452 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9953
5450/5452 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9952
5452/5452 [==============================] - 3s 630us/step - loss: 0.0251 - acc: 0.9952 - val_loss: 0.3814 - val_acc: 0.9020

Epoch 00006: val_acc did not improve from 0.91400
Epoch 7/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0302 - acc: 0.9800
 150/5452 [..............................] - ETA: 3s - loss: 0.0303 - acc: 0.9867
 250/5452 [>.............................] - ETA: 3s - loss: 0.0207 - acc: 0.9920
 350/5452 [>.............................] - ETA: 3s - loss: 0.0189 - acc: 0.9943
 450/5452 [=>............................] - ETA: 3s - loss: 0.0177 - acc: 0.9956
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0156 - acc: 0.9964
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0141 - acc: 0.9969
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0210 - acc: 0.9960
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0200 - acc: 0.9965
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0200 - acc: 0.9958
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0184 - acc: 0.9962
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0214 - acc: 0.9957
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0206 - acc: 0.9960
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0194 - acc: 0.9963
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0182 - acc: 0.9966
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0175 - acc: 0.9968
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0168 - acc: 0.9970
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0191 - acc: 0.9966
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0185 - acc: 0.9968
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0178 - acc: 0.9969
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0175 - acc: 0.9971
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0171 - acc: 0.9972
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0167 - acc: 0.9973
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0166 - acc: 0.9970
2450/5452 [============>.................] - ETA: 1s - loss: 0.0161 - acc: 0.9971
2550/5452 [=============>................] - ETA: 1s - loss: 0.0158 - acc: 0.9973
2650/5452 [=============>................] - ETA: 1s - loss: 0.0155 - acc: 0.9974
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0160 - acc: 0.9971
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0159 - acc: 0.9972
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0156 - acc: 0.9973
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0155 - acc: 0.9974
3150/5452 [================>.............] - ETA: 1s - loss: 0.0154 - acc: 0.9975
3250/5452 [================>.............] - ETA: 1s - loss: 0.0151 - acc: 0.9975
3350/5452 [=================>............] - ETA: 1s - loss: 0.0149 - acc: 0.9976
3450/5452 [=================>............] - ETA: 1s - loss: 0.0147 - acc: 0.9977
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0145 - acc: 0.9977
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0142 - acc: 0.9978
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0140 - acc: 0.9979
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0137 - acc: 0.9979
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0135 - acc: 0.9980
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0133 - acc: 0.9980
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0131 - acc: 0.9981
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0129 - acc: 0.9981
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0128 - acc: 0.9982
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0126 - acc: 0.9982
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0124 - acc: 0.9982
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0123 - acc: 0.9983
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0147 - acc: 0.9981
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0145 - acc: 0.9981
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0145 - acc: 0.9980
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0143 - acc: 0.9980
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9981
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0140 - acc: 0.9981
5350/5452 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9981
5450/5452 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9980
5452/5452 [==============================] - 3s 627us/step - loss: 0.0141 - acc: 0.9980 - val_loss: 0.3349 - val_acc: 0.9200

Epoch 00007: val_acc improved from 0.91400 to 0.92000, saving model to word2vec_main_model.h5
Epoch 8/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0030 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0045 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0056 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0051 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0053 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0055 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0051 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0050 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0052 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0066 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0069 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0074 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0133 - acc: 0.9976
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0126 - acc: 0.9978
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0118 - acc: 0.9979
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0114 - acc: 0.9981
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0111 - acc: 0.9982
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0118 - acc: 0.9977
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0127 - acc: 0.9973
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0125 - acc: 0.9974
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0127 - acc: 0.9971
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0134 - acc: 0.9967
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0133 - acc: 0.9969
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0129 - acc: 0.9970
2450/5452 [============>.................] - ETA: 1s - loss: 0.0152 - acc: 0.9967
2550/5452 [=============>................] - ETA: 1s - loss: 0.0155 - acc: 0.9965
2650/5452 [=============>................] - ETA: 1s - loss: 0.0150 - acc: 0.9966
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0146 - acc: 0.9967
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0148 - acc: 0.9965
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0148 - acc: 0.9966
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0144 - acc: 0.9967
3150/5452 [================>.............] - ETA: 1s - loss: 0.0147 - acc: 0.9965
3250/5452 [================>.............] - ETA: 1s - loss: 0.0154 - acc: 0.9963
3350/5452 [=================>............] - ETA: 1s - loss: 0.0151 - acc: 0.9964
3450/5452 [=================>............] - ETA: 1s - loss: 0.0149 - acc: 0.9965
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0147 - acc: 0.9966
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0144 - acc: 0.9967
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0142 - acc: 0.9968
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0145 - acc: 0.9966
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0144 - acc: 0.9967
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0156 - acc: 0.9965
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0158 - acc: 0.9964
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0155 - acc: 0.9965
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0152 - acc: 0.9966
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0153 - acc: 0.9966
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0151 - acc: 0.9967
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0155 - acc: 0.9966
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0153 - acc: 0.9966
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0155 - acc: 0.9965
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0154 - acc: 0.9966
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0155 - acc: 0.9964
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0155 - acc: 0.9965
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0153 - acc: 0.9966
5350/5452 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9964
5450/5452 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9961
5452/5452 [==============================] - 3s 624us/step - loss: 0.0162 - acc: 0.9961 - val_loss: 0.3300 - val_acc: 0.9160

Epoch 00008: val_acc did not improve from 0.92000
Epoch 9/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0127 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0081 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0076 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0075 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0125 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0175 - acc: 0.9927
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0160 - acc: 0.9938
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0144 - acc: 0.9947
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0132 - acc: 0.9953
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0127 - acc: 0.9958
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0180 - acc: 0.9943
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0204 - acc: 0.9939
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0190 - acc: 0.9944
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0182 - acc: 0.9948
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0177 - acc: 0.9945
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0174 - acc: 0.9948
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0168 - acc: 0.9952
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0212 - acc: 0.9931
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0208 - acc: 0.9935
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0204 - acc: 0.9938
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0208 - acc: 0.9937
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0208 - acc: 0.9940
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0201 - acc: 0.9942
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0207 - acc: 0.9936
2450/5452 [============>.................] - ETA: 1s - loss: 0.0201 - acc: 0.9939
2550/5452 [=============>................] - ETA: 1s - loss: 0.0199 - acc: 0.9941
2650/5452 [=============>................] - ETA: 1s - loss: 0.0206 - acc: 0.9936
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0204 - acc: 0.9938
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0225 - acc: 0.9926
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0245 - acc: 0.9922
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0248 - acc: 0.9921
3150/5452 [================>.............] - ETA: 1s - loss: 0.0247 - acc: 0.9924
3250/5452 [================>.............] - ETA: 1s - loss: 0.0258 - acc: 0.9920
3350/5452 [=================>............] - ETA: 1s - loss: 0.0271 - acc: 0.9916
3450/5452 [=================>............] - ETA: 1s - loss: 0.0282 - acc: 0.9910
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0277 - acc: 0.9913
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0280 - acc: 0.9912
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0279 - acc: 0.9912
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0283 - acc: 0.9912
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0290 - acc: 0.9906
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0302 - acc: 0.9901
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0315 - acc: 0.9896
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0325 - acc: 0.9892
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0327 - acc: 0.9892
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0325 - acc: 0.9894
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0329 - acc: 0.9895
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0328 - acc: 0.9895
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0325 - acc: 0.9897
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0319 - acc: 0.9899
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0328 - acc: 0.9899
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0329 - acc: 0.9895
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0329 - acc: 0.9895
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0327 - acc: 0.9897
5350/5452 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9899
5450/5452 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9899
5452/5452 [==============================] - 3s 623us/step - loss: 0.0325 - acc: 0.9899 - val_loss: 0.4945 - val_acc: 0.9040

Epoch 00009: val_acc did not improve from 0.92000
Epoch 10/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0325 - acc: 0.9800
 150/5452 [..............................] - ETA: 3s - loss: 0.1240 - acc: 0.9533
 250/5452 [>.............................] - ETA: 3s - loss: 0.2466 - acc: 0.9360
 350/5452 [>.............................] - ETA: 3s - loss: 0.1967 - acc: 0.9514
 450/5452 [=>............................] - ETA: 3s - loss: 0.1884 - acc: 0.9489
 550/5452 [==>...........................] - ETA: 2s - loss: 0.1961 - acc: 0.9455
 650/5452 [==>...........................] - ETA: 2s - loss: 0.1880 - acc: 0.9462
 750/5452 [===>..........................] - ETA: 2s - loss: 0.1863 - acc: 0.9467
 850/5452 [===>..........................] - ETA: 2s - loss: 0.1832 - acc: 0.9459
 950/5452 [====>.........................] - ETA: 2s - loss: 0.1814 - acc: 0.9463
1050/5452 [====>.........................] - ETA: 2s - loss: 0.1719 - acc: 0.9486
1150/5452 [=====>........................] - ETA: 2s - loss: 0.1781 - acc: 0.9478
1250/5452 [=====>........................] - ETA: 2s - loss: 0.1815 - acc: 0.9480
1350/5452 [======>.......................] - ETA: 2s - loss: 0.1794 - acc: 0.9496
1450/5452 [======>.......................] - ETA: 2s - loss: 0.1722 - acc: 0.9517
1550/5452 [=======>......................] - ETA: 2s - loss: 0.1705 - acc: 0.9523
1650/5452 [========>.....................] - ETA: 2s - loss: 0.1754 - acc: 0.9521
1750/5452 [========>.....................] - ETA: 2s - loss: 0.1799 - acc: 0.9509
1850/5452 [=========>....................] - ETA: 2s - loss: 0.1838 - acc: 0.9497
1950/5452 [=========>....................] - ETA: 2s - loss: 0.1779 - acc: 0.9508
2050/5452 [==========>...................] - ETA: 2s - loss: 0.1727 - acc: 0.9512
2150/5452 [==========>...................] - ETA: 2s - loss: 0.1730 - acc: 0.9516
2250/5452 [===========>..................] - ETA: 1s - loss: 0.1691 - acc: 0.9520
2350/5452 [===========>..................] - ETA: 1s - loss: 0.1639 - acc: 0.9528
2450/5452 [============>.................] - ETA: 1s - loss: 0.1632 - acc: 0.9522
2550/5452 [=============>................] - ETA: 1s - loss: 0.1605 - acc: 0.9525
2650/5452 [=============>................] - ETA: 1s - loss: 0.1634 - acc: 0.9528
2750/5452 [==============>...............] - ETA: 1s - loss: 0.1641 - acc: 0.9535
2850/5452 [==============>...............] - ETA: 1s - loss: 0.1628 - acc: 0.9547
2950/5452 [===============>..............] - ETA: 1s - loss: 0.1596 - acc: 0.9556
3050/5452 [===============>..............] - ETA: 1s - loss: 0.1571 - acc: 0.9557
3150/5452 [================>.............] - ETA: 1s - loss: 0.1555 - acc: 0.9556
3250/5452 [================>.............] - ETA: 1s - loss: 0.1541 - acc: 0.9560
3350/5452 [=================>............] - ETA: 1s - loss: 0.1525 - acc: 0.9567
3450/5452 [=================>............] - ETA: 1s - loss: 0.1492 - acc: 0.9577
3550/5452 [==================>...........] - ETA: 1s - loss: 0.1467 - acc: 0.9580
3650/5452 [===================>..........] - ETA: 1s - loss: 0.1464 - acc: 0.9581
3750/5452 [===================>..........] - ETA: 1s - loss: 0.1433 - acc: 0.9587
3850/5452 [====================>.........] - ETA: 0s - loss: 0.1435 - acc: 0.9582
3950/5452 [====================>.........] - ETA: 0s - loss: 0.1408 - acc: 0.9590
4050/5452 [=====================>........] - ETA: 0s - loss: 0.1399 - acc: 0.9588
4150/5452 [=====================>........] - ETA: 0s - loss: 0.1395 - acc: 0.9588
4250/5452 [======================>.......] - ETA: 0s - loss: 0.1387 - acc: 0.9593
4350/5452 [======================>.......] - ETA: 0s - loss: 0.1369 - acc: 0.9600
4450/5452 [=======================>......] - ETA: 0s - loss: 0.1366 - acc: 0.9602
4550/5452 [========================>.....] - ETA: 0s - loss: 0.1371 - acc: 0.9600
4650/5452 [========================>.....] - ETA: 0s - loss: 0.1360 - acc: 0.9604
4750/5452 [=========================>....] - ETA: 0s - loss: 0.1353 - acc: 0.9608
4850/5452 [=========================>....] - ETA: 0s - loss: 0.1356 - acc: 0.9606
4950/5452 [==========================>...] - ETA: 0s - loss: 0.1335 - acc: 0.9610
5050/5452 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9614
5150/5452 [===========================>..] - ETA: 0s - loss: 0.1311 - acc: 0.9616
5250/5452 [===========================>..] - ETA: 0s - loss: 0.1321 - acc: 0.9613
5350/5452 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9615
5450/5452 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9615
5452/5452 [==============================] - 3s 623us/step - loss: 0.1301 - acc: 0.9615 - val_loss: 0.3495 - val_acc: 0.9140

Epoch 00010: val_acc did not improve from 0.92000
Epoch 11/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0869 - acc: 0.9600
 150/5452 [..............................] - ETA: 3s - loss: 0.1230 - acc: 0.9667
 250/5452 [>.............................] - ETA: 3s - loss: 0.0777 - acc: 0.9800
 350/5452 [>.............................] - ETA: 3s - loss: 0.0586 - acc: 0.9857
 450/5452 [=>............................] - ETA: 3s - loss: 0.0557 - acc: 0.9844
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0688 - acc: 0.9836
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0613 - acc: 0.9862
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0555 - acc: 0.9867
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0601 - acc: 0.9847
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0550 - acc: 0.9863
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0526 - acc: 0.9867
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0546 - acc: 0.9852
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0582 - acc: 0.9840
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0560 - acc: 0.9844
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0539 - acc: 0.9848
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0516 - acc: 0.9852
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0508 - acc: 0.9842
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0493 - acc: 0.9846
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0475 - acc: 0.9849
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0460 - acc: 0.9856
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0477 - acc: 0.9854
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0479 - acc: 0.9847
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0487 - acc: 0.9840
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0480 - acc: 0.9838
2450/5452 [============>.................] - ETA: 1s - loss: 0.0488 - acc: 0.9837
2550/5452 [=============>................] - ETA: 1s - loss: 0.0486 - acc: 0.9839
2650/5452 [=============>................] - ETA: 1s - loss: 0.0474 - acc: 0.9845
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0484 - acc: 0.9844
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0486 - acc: 0.9842
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0474 - acc: 0.9847
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0465 - acc: 0.9849
3150/5452 [================>.............] - ETA: 1s - loss: 0.0458 - acc: 0.9851
3250/5452 [================>.............] - ETA: 1s - loss: 0.0460 - acc: 0.9846
3350/5452 [=================>............] - ETA: 1s - loss: 0.0449 - acc: 0.9851
3450/5452 [=================>............] - ETA: 1s - loss: 0.0439 - acc: 0.9855
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0429 - acc: 0.9859
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0475 - acc: 0.9855
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0466 - acc: 0.9859
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0455 - acc: 0.9862
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0464 - acc: 0.9861
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0456 - acc: 0.9864
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0448 - acc: 0.9867
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0441 - acc: 0.9871
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0436 - acc: 0.9869
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0445 - acc: 0.9865
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0446 - acc: 0.9864
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0450 - acc: 0.9862
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0441 - acc: 0.9865
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0440 - acc: 0.9866
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0432 - acc: 0.9869
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0427 - acc: 0.9871
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0424 - acc: 0.9872
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0418 - acc: 0.9874
5350/5452 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9875
5450/5452 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9872
5452/5452 [==============================] - 3s 624us/step - loss: 0.0418 - acc: 0.9872 - val_loss: 0.3806 - val_acc: 0.9080

Epoch 00011: val_acc did not improve from 0.92000
Epoch 12/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0077 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0134 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0138 - acc: 0.9960
 350/5452 [>.............................] - ETA: 3s - loss: 0.0123 - acc: 0.9971
 450/5452 [=>............................] - ETA: 3s - loss: 0.0142 - acc: 0.9956
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0149 - acc: 0.9964
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0148 - acc: 0.9969
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0141 - acc: 0.9973
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0139 - acc: 0.9965
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0132 - acc: 0.9968
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0124 - acc: 0.9971
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0121 - acc: 0.9974
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0116 - acc: 0.9976
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0135 - acc: 0.9970
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0132 - acc: 0.9972
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0127 - acc: 0.9974
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0121 - acc: 0.9976
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0117 - acc: 0.9977
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0122 - acc: 0.9973
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0121 - acc: 0.9974
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0140 - acc: 0.9961
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0136 - acc: 0.9963
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0133 - acc: 0.9964
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0128 - acc: 0.9966
2450/5452 [============>.................] - ETA: 1s - loss: 0.0176 - acc: 0.9955
2550/5452 [=============>................] - ETA: 1s - loss: 0.0173 - acc: 0.9957
2650/5452 [=============>................] - ETA: 1s - loss: 0.0172 - acc: 0.9955
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0169 - acc: 0.9956
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0168 - acc: 0.9958
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0188 - acc: 0.9953
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0189 - acc: 0.9951
3150/5452 [================>.............] - ETA: 1s - loss: 0.0192 - acc: 0.9949
3250/5452 [================>.............] - ETA: 1s - loss: 0.0189 - acc: 0.9951
3350/5452 [=================>............] - ETA: 1s - loss: 0.0185 - acc: 0.9952
3450/5452 [=================>............] - ETA: 1s - loss: 0.0181 - acc: 0.9954
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0191 - acc: 0.9952
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0194 - acc: 0.9951
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0193 - acc: 0.9949
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0195 - acc: 0.9948
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0204 - acc: 0.9944
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0216 - acc: 0.9941
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0233 - acc: 0.9937
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0238 - acc: 0.9934
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0239 - acc: 0.9933
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0235 - acc: 0.9935
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0236 - acc: 0.9934
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0245 - acc: 0.9931
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0244 - acc: 0.9933
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0249 - acc: 0.9928
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0268 - acc: 0.9925
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0266 - acc: 0.9925
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0280 - acc: 0.9922
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0294 - acc: 0.9922
5350/5452 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9921
5450/5452 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9923
5452/5452 [==============================] - 3s 623us/step - loss: 0.0288 - acc: 0.9923 - val_loss: 0.7090 - val_acc: 0.8740

Epoch 00012: val_acc did not improve from 0.92000

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 13/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0760 - acc: 0.9800
 150/5452 [..............................] - ETA: 3s - loss: 0.0308 - acc: 0.9933
 250/5452 [>.............................] - ETA: 3s - loss: 0.0329 - acc: 0.9920
 350/5452 [>.............................] - ETA: 3s - loss: 0.0277 - acc: 0.9914
 450/5452 [=>............................] - ETA: 3s - loss: 0.0241 - acc: 0.9933
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0221 - acc: 0.9945
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0211 - acc: 0.9938
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0188 - acc: 0.9947
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0205 - acc: 0.9929
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0188 - acc: 0.9937
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0174 - acc: 0.9943
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0161 - acc: 0.9948
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0172 - acc: 0.9936
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0166 - acc: 0.9941
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0160 - acc: 0.9945
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0220 - acc: 0.9942
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0222 - acc: 0.9939
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0214 - acc: 0.9943
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0204 - acc: 0.9946
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0197 - acc: 0.9949
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0192 - acc: 0.9951
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0185 - acc: 0.9953
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0182 - acc: 0.9951
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0180 - acc: 0.9949
2450/5452 [============>.................] - ETA: 1s - loss: 0.0174 - acc: 0.9951
2550/5452 [=============>................] - ETA: 1s - loss: 0.0174 - acc: 0.9953
2650/5452 [=============>................] - ETA: 1s - loss: 0.0168 - acc: 0.9955
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0183 - acc: 0.9953
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0182 - acc: 0.9951
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0177 - acc: 0.9953
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0178 - acc: 0.9951
3150/5452 [================>.............] - ETA: 1s - loss: 0.0173 - acc: 0.9952
3250/5452 [================>.............] - ETA: 1s - loss: 0.0168 - acc: 0.9954
3350/5452 [=================>............] - ETA: 1s - loss: 0.0169 - acc: 0.9952
3450/5452 [=================>............] - ETA: 1s - loss: 0.0167 - acc: 0.9954
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0166 - acc: 0.9952
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0163 - acc: 0.9953
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0160 - acc: 0.9955
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0159 - acc: 0.9956
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0156 - acc: 0.9957
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0154 - acc: 0.9958
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0151 - acc: 0.9959
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0152 - acc: 0.9958
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0149 - acc: 0.9959
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0147 - acc: 0.9960
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0145 - acc: 0.9960
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0143 - acc: 0.9961
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0141 - acc: 0.9962
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0142 - acc: 0.9961
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0142 - acc: 0.9960
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0144 - acc: 0.9958
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9959
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0140 - acc: 0.9960
5350/5452 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9961
5450/5452 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9961
5452/5452 [==============================] - 3s 625us/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.4001 - val_acc: 0.9240

Epoch 00013: val_acc improved from 0.92000 to 0.92400, saving model to word2vec_main_model.h5
Epoch 14/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0076 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0049 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0055 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0047 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0041 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0038 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0083 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0087 - acc: 0.9973
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0081 - acc: 0.9976
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0075 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0071 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0067 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0065 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0064 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0061 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0058 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0074 - acc: 0.9982
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0109 - acc: 0.9966
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0150 - acc: 0.9962
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0148 - acc: 0.9964
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0145 - acc: 0.9966
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0141 - acc: 0.9967
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0136 - acc: 0.9969
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0132 - acc: 0.9970
2450/5452 [============>.................] - ETA: 1s - loss: 0.0127 - acc: 0.9971
2550/5452 [=============>................] - ETA: 1s - loss: 0.0124 - acc: 0.9973
2650/5452 [=============>................] - ETA: 1s - loss: 0.0121 - acc: 0.9974
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0118 - acc: 0.9975
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0114 - acc: 0.9975
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0112 - acc: 0.9976
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0115 - acc: 0.9974
3150/5452 [================>.............] - ETA: 1s - loss: 0.0113 - acc: 0.9975
3250/5452 [================>.............] - ETA: 1s - loss: 0.0111 - acc: 0.9975
3350/5452 [=================>............] - ETA: 1s - loss: 0.0109 - acc: 0.9976
3450/5452 [=================>............] - ETA: 1s - loss: 0.0111 - acc: 0.9974
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0109 - acc: 0.9975
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0107 - acc: 0.9975
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0105 - acc: 0.9976
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0103 - acc: 0.9977
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0101 - acc: 0.9977
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0100 - acc: 0.9978
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0099 - acc: 0.9978
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0098 - acc: 0.9979
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0096 - acc: 0.9979
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0095 - acc: 0.9980
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0094 - acc: 0.9980
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0093 - acc: 0.9981
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0091 - acc: 0.9981
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0090 - acc: 0.9981
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0090 - acc: 0.9980
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0089 - acc: 0.9980
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9981
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0087 - acc: 0.9981
5350/5452 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9981
5450/5452 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9982
5452/5452 [==============================] - 3s 624us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.4062 - val_acc: 0.9220

Epoch 00014: val_acc did not improve from 0.92400
Epoch 15/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0130 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0064 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0053 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0044 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0082 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0077 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0068 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0061 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0071 - acc: 0.9976
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0066 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0061 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0058 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0055 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0053 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0050 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0049 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0047 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0045 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0044 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0049 - acc: 0.9985
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0047 - acc: 0.9985
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0045 - acc: 0.9986
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0044 - acc: 0.9987
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0043 - acc: 0.9987
2450/5452 [============>.................] - ETA: 1s - loss: 0.0044 - acc: 0.9988
2550/5452 [=============>................] - ETA: 1s - loss: 0.0044 - acc: 0.9988
2650/5452 [=============>................] - ETA: 1s - loss: 0.0043 - acc: 0.9989
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0043 - acc: 0.9989
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0043 - acc: 0.9989
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0042 - acc: 0.9990
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0048 - acc: 0.9984
3150/5452 [================>.............] - ETA: 1s - loss: 0.0048 - acc: 0.9984
3250/5452 [================>.............] - ETA: 1s - loss: 0.0047 - acc: 0.9985
3350/5452 [=================>............] - ETA: 1s - loss: 0.0046 - acc: 0.9985
3450/5452 [=================>............] - ETA: 1s - loss: 0.0045 - acc: 0.9986
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0045 - acc: 0.9986
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0044 - acc: 0.9986
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0044 - acc: 0.9987
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0044 - acc: 0.9987
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0043 - acc: 0.9987
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0043 - acc: 0.9988
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0043 - acc: 0.9988
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0043 - acc: 0.9988
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0042 - acc: 0.9989
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0046 - acc: 0.9987
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0046 - acc: 0.9987
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0046 - acc: 0.9987
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 0.9987
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 0.9988
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 0.9988
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 0.9988
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9988
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0062 - acc: 0.9987
5350/5452 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9987
5450/5452 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9987
5452/5452 [==============================] - 3s 625us/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.3743 - val_acc: 0.9260

Epoch 00015: val_acc improved from 0.92400 to 0.92600, saving model to word2vec_main_model.h5
Epoch 16/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0036 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0022 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0019 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0020 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0024 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0027 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0026 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0026 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0025 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0024 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0025 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0024 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0028 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0029 - acc: 1.0000
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0029 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0028 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0028 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0028 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0028 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0027 - acc: 1.0000
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0051 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0050 - acc: 0.9996
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0049 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0048 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0047 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0046 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0052 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0051 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0052 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0052 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0051 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0051 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0050 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0051 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0052 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0051 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0050 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0050 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0049 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0048 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0048 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0047 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0047 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0046 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0046 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9994
5452/5452 [==============================] - 3s 626us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.3642 - val_acc: 0.9240

Epoch 00016: val_acc did not improve from 0.92600
Epoch 17/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0016 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0024 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0110 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0093 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0085 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0077 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0072 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0067 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0061 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0059 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0056 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0057 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0057 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0056 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0054 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0066 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0063 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0061 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0058 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0058 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0056 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0054 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0054 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0065 - acc: 0.9988
2650/5452 [=============>................] - ETA: 1s - loss: 0.0063 - acc: 0.9989
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0062 - acc: 0.9989
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0060 - acc: 0.9989
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0059 - acc: 0.9990
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0058 - acc: 0.9990
3150/5452 [================>.............] - ETA: 1s - loss: 0.0057 - acc: 0.9990
3250/5452 [================>.............] - ETA: 1s - loss: 0.0056 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0055 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0054 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0053 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0052 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0051 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0050 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0049 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0048 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0048 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0047 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0046 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0046 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0046 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0046 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0045 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9994
5452/5452 [==============================] - 3s 625us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.3562 - val_acc: 0.9280

Epoch 00017: val_acc improved from 0.92600 to 0.92800, saving model to word2vec_main_model.h5
Epoch 18/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0023 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0035 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0029 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0024 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0077 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 3s - loss: 0.0064 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0060 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0055 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0098 - acc: 0.9976
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0089 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0082 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0083 - acc: 0.9974
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0079 - acc: 0.9976
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0075 - acc: 0.9978
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0071 - acc: 0.9979
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0067 - acc: 0.9981
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0064 - acc: 0.9982
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0061 - acc: 0.9983
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0059 - acc: 0.9984
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0056 - acc: 0.9985
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0055 - acc: 0.9985
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0054 - acc: 0.9986
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0053 - acc: 0.9987
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0052 - acc: 0.9987
2450/5452 [============>.................] - ETA: 1s - loss: 0.0051 - acc: 0.9988
2550/5452 [=============>................] - ETA: 1s - loss: 0.0050 - acc: 0.9988
2650/5452 [=============>................] - ETA: 1s - loss: 0.0050 - acc: 0.9989
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0048 - acc: 0.9989
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0047 - acc: 0.9989
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0046 - acc: 0.9990
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0046 - acc: 0.9990
3150/5452 [================>.............] - ETA: 1s - loss: 0.0045 - acc: 0.9990
3250/5452 [================>.............] - ETA: 1s - loss: 0.0044 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0043 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0043 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0042 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0041 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0041 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0041 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0041 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0041 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0040 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0039 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0040 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0054 - acc: 0.9991
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0053 - acc: 0.9991
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0052 - acc: 0.9991
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0051 - acc: 0.9992
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0050 - acc: 0.9992
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 0.9990
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 0.9990
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9990
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9990
5350/5452 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9991
5450/5452 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9989
5452/5452 [==============================] - 3s 627us/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.3386 - val_acc: 0.9320

Epoch 00018: val_acc improved from 0.92800 to 0.93200, saving model to word2vec_main_model.h5
Epoch 19/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0036 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0022 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0018 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0025 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0022 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0029 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0040 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0039 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0040 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0040 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0039 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0038 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0037 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0037 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0036 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0037 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0036 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0036 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0035 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0035 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0034 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0034 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0045 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0044 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0044 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0043 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0043 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0042 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0048 - acc: 0.9992
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0047 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9993
5452/5452 [==============================] - 3s 628us/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.3611 - val_acc: 0.9280

Epoch 00019: val_acc did not improve from 0.93200
Epoch 20/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0020 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0019 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0016 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0014 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0014 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0018 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0017 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0017 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0018 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0022 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0021 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0022 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0022 - acc: 1.0000
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0022 - acc: 1.0000
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0022 - acc: 1.0000
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 1.0000
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 1.0000
3150/5452 [================>.............] - ETA: 1s - loss: 0.0021 - acc: 1.0000
3250/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 1.0000
3350/5452 [=================>............] - ETA: 1s - loss: 0.0020 - acc: 1.0000
3450/5452 [=================>............] - ETA: 1s - loss: 0.0020 - acc: 1.0000
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0027 - acc: 0.9997
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0026 - acc: 0.9997
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0026 - acc: 0.9997
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0036 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0036 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0035 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0035 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0035 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0040 - acc: 0.9991
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0040 - acc: 0.9992
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0039 - acc: 0.9992
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0039 - acc: 0.9992
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0038 - acc: 0.9992
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0038 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0037 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993
5452/5452 [==============================] - 3s 624us/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.3613 - val_acc: 0.9280

Epoch 00020: val_acc did not improve from 0.93200
Epoch 21/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0030 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0027 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0025 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0022 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0034 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0031 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0027 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0025 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0031 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0030 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0030 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0028 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0029 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0028 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0027 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0038 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0036 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0035 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0034 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0033 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0034 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0033 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0032 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0032 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0031 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0030 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0030 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0030 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0029 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0029 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0032 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0032 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0031 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0031 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0031 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0030 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0029 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0029 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0029 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5452/5452 [==============================] - 3s 625us/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.3784 - val_acc: 0.9260

Epoch 00021: val_acc did not improve from 0.93200
Epoch 22/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0028 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0018 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0015 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0050 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0044 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0039 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0035 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0079 - acc: 0.9976
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0079 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0072 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0068 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0063 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0060 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0056 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0053 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0051 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0054 - acc: 0.9983
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0052 - acc: 0.9984
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0050 - acc: 0.9985
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0050 - acc: 0.9985
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0048 - acc: 0.9986
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0047 - acc: 0.9987
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0046 - acc: 0.9987
2450/5452 [============>.................] - ETA: 1s - loss: 0.0045 - acc: 0.9988
2550/5452 [=============>................] - ETA: 1s - loss: 0.0043 - acc: 0.9988
2650/5452 [=============>................] - ETA: 1s - loss: 0.0043 - acc: 0.9989
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0042 - acc: 0.9989
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0040 - acc: 0.9989
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0040 - acc: 0.9990
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0039 - acc: 0.9990
3150/5452 [================>.............] - ETA: 1s - loss: 0.0038 - acc: 0.9990
3250/5452 [================>.............] - ETA: 1s - loss: 0.0039 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0038 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0037 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0037 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0036 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0036 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0035 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0035 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0042 - acc: 0.9991
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0041 - acc: 0.9991
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0046 - acc: 0.9989
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0045 - acc: 0.9989
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0045 - acc: 0.9989
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0044 - acc: 0.9989
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0043 - acc: 0.9990
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0043 - acc: 0.9990
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 0.9990
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0042 - acc: 0.9990
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0041 - acc: 0.9990
5350/5452 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9991
5450/5452 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9991
5452/5452 [==============================] - 3s 626us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.3472 - val_acc: 0.9340

Epoch 00022: val_acc improved from 0.93200 to 0.93400, saving model to word2vec_main_model.h5
Epoch 23/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0031 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0116 - acc: 0.9933
 250/5452 [>.............................] - ETA: 3s - loss: 0.0075 - acc: 0.9960
 350/5452 [>.............................] - ETA: 3s - loss: 0.0058 - acc: 0.9971
 450/5452 [=>............................] - ETA: 3s - loss: 0.0050 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0044 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0039 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0035 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0035 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0034 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0051 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0047 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0046 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0044 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0041 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0039 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0038 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0036 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0035 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0034 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0032 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0032 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0031 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0030 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0029 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0029 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0029 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0028 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0027 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0027 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0026 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0026 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0026 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0025 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0025 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0025 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0025 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0026 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0025 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0025 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0025 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0024 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0023 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0023 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0023 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0023 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0023 - acc: 0.9996
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 0.9996
5350/5452 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996
5450/5452 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996
5452/5452 [==============================] - 3s 626us/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.3692 - val_acc: 0.9260

Epoch 00023: val_acc did not improve from 0.93400
Epoch 24/200

  50/5452 [..............................] - ETA: 3s - loss: 5.6751e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 7.6568e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 9.4057e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0136 - acc: 0.9971    
 450/5452 [=>............................] - ETA: 3s - loss: 0.0108 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0094 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0081 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0072 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0066 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0061 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0056 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0052 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0049 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0047 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0045 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0043 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0041 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0040 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0075 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0072 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0069 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0066 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0063 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0062 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0060 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0059 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0057 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0055 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0054 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0052 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0051 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0050 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0049 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0047 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0046 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0045 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0044 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0043 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0043 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0042 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0041 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0041 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0040 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0039 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0039 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0039 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0038 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0038 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0037 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0037 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0036 - acc: 0.9996
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 0.9996
5350/5452 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9994
5452/5452 [==============================] - 3s 625us/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.3626 - val_acc: 0.9300

Epoch 00024: val_acc did not improve from 0.93400
Epoch 25/200

  50/5452 [..............................] - ETA: 3s - loss: 6.7038e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 6.2276e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 8.6602e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 8.4754e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 8.5038e-04 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 8.7306e-04 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0011 - acc: 1.0000    
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0031 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0030 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0028 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0028 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0026 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0025 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0024 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0024 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0023 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0024 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0023 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0024 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0023 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0023 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0022 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0022 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0021 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0021 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0021 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0020 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0020 - acc: 0.9996
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0025 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0024 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0024 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0024 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0023 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0024 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0037 - acc: 0.9991
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0036 - acc: 0.9991
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0036 - acc: 0.9991
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0035 - acc: 0.9992
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0035 - acc: 0.9992
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0034 - acc: 0.9992
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0034 - acc: 0.9992
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9993
5452/5452 [==============================] - 3s 626us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.3624 - val_acc: 0.9320

Epoch 00025: val_acc did not improve from 0.93400
Epoch 26/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0015 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0060 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0040 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0057 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0046 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0041 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0040 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0037 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0069 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0064 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0059 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0056 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0052 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0050 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0048 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0045 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0044 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0045 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0043 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0041 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0039 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0039 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0038 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0036 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0036 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0035 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0034 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0033 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0032 - acc: 0.9996
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0032 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0031 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0030 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0030 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0029 - acc: 0.9997
3450/5452 [=================>............] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0027 - acc: 0.9997
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9997
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9997
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9998
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0027 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0027 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0029 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5452/5452 [==============================] - 3s 628us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.3824 - val_acc: 0.9300

Epoch 00026: val_acc did not improve from 0.93400
Epoch 27/200

  50/5452 [..............................] - ETA: 3s - loss: 7.0372e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000    
 250/5452 [>.............................] - ETA: 3s - loss: 0.0011 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 9.5143e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000    
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0037 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0036 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0034 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0033 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0031 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0030 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0028 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0027 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0026 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0026 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0025 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0025 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0025 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0024 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0024 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0024 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0036 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0035 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0034 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0033 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0033 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0032 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0031 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0031 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0030 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0029 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0029 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0028 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0028 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0028 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0028 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0030 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0029 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993
5452/5452 [==============================] - 3s 624us/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.3810 - val_acc: 0.9300

Epoch 00027: val_acc did not improve from 0.93400

Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 28/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0013 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0011 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0010 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0011 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0060 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0057 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0064 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0061 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0058 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0055 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0053 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0050 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0049 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0048 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0046 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0044 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0043 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0042 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0040 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0039 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0038 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0037 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0036 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0036 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0035 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0034 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0034 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0033 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0033 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0032 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0034 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0034 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0034 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0033 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0032 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0032 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0033 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0032 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0032 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0031 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0031 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9994
5452/5452 [==============================] - 3s 629us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.3754 - val_acc: 0.9260

Epoch 00028: val_acc did not improve from 0.93400
Epoch 29/200

  50/5452 [..............................] - ETA: 3s - loss: 7.8503e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 8.3425e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 6.7487e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 6.6810e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0097 - acc: 0.9978    
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0080 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0070 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0062 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0059 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0057 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0053 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0050 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0046 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0048 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0045 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0044 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0042 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0040 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0039 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0039 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0038 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0043 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0041 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0040 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0039 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0038 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0038 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0037 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0036 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0035 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0035 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0034 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0033 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0034 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0033 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0033 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0032 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0031 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0031 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0030 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0030 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0030 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0029 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0029 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0029 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0028 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0028 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0027 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0027 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0026 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5452/5452 [==============================] - 3s 627us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.3805 - val_acc: 0.9260

Epoch 00029: val_acc did not improve from 0.93400
Epoch 30/200

  50/5452 [..............................] - ETA: 3s - loss: 4.8120e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 6.4488e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 6.4011e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 6.8200e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000    
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0011 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0011 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0022 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0028 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0027 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0025 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0024 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0022 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0021 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0022 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0021 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0020 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0020 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0019 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0018 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0018 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0018 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0017 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0016 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0016 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0016 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0016 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0017 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0017 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0017 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0017 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0016 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0016 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0016 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0016 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0016 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0015 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0016 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0016 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0016 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 0.9996
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 0.9996
5350/5452 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996
5450/5452 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996
5452/5452 [==============================] - 3s 627us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.3829 - val_acc: 0.9280

Epoch 00030: val_acc did not improve from 0.93400
Epoch 31/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0014 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0010 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 9.3420e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 9.9609e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 9.6040e-04 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 9.2718e-04 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0010 - acc: 1.0000    
 750/5452 [===>..........................] - ETA: 2s - loss: 9.9442e-04 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 9.4925e-04 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 9.0050e-04 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 8.5916e-04 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 9.1309e-04 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 9.0527e-04 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 9.7538e-04 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 9.6387e-04 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 9.4983e-04 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 9.8505e-04 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 9.7720e-04 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 9.8673e-04 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 9.8634e-04 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0010 - acc: 1.0000    
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0010 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0010 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0010 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0011 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0011 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0020 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0020 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0019 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0019 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0019 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0019 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0019 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0018 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0018 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0018 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0018 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0017 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0017 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0020 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993
5452/5452 [==============================] - 3s 630us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.3877 - val_acc: 0.9300

Epoch 00031: val_acc did not improve from 0.93400
Epoch 32/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0013 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0014 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0011 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0011 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0016 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0016 - acc: 1.0000
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3150/5452 [================>.............] - ETA: 1s - loss: 0.0016 - acc: 1.0000
3250/5452 [================>.............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3350/5452 [=================>............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3450/5452 [=================>............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0015 - acc: 1.0000
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0015 - acc: 1.0000
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0018 - acc: 0.9997
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0018 - acc: 0.9998
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0018 - acc: 0.9998
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0020 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0020 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0019 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0019 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0019 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0018 - acc: 0.9996
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0018 - acc: 0.9996
5350/5452 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996
5450/5452 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996
5452/5452 [==============================] - 3s 627us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.3844 - val_acc: 0.9280

Epoch 00032: val_acc did not improve from 0.93400

Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 33/200

  50/5452 [..............................] - ETA: 3s - loss: 4.1069e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 7.8564e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 7.7916e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000    
 450/5452 [=>............................] - ETA: 3s - loss: 0.0028 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0028 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0025 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0021 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0018 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0018 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0023 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0054 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0051 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0049 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0047 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0045 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0043 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0042 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0040 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0039 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0038 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0036 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0035 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0035 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0034 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0033 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0033 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0032 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0031 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0031 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0030 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0030 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0029 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0028 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0028 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0027 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0027 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0026 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0026 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0025 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0025 - acc: 0.9996
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0025 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0034 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994
5452/5452 [==============================] - 3s 623us/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.3823 - val_acc: 0.9280

Epoch 00033: val_acc did not improve from 0.93400
Epoch 34/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0013 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 8.4964e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 7.6649e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0020 - acc: 1.0000    
 450/5452 [=>............................] - ETA: 3s - loss: 0.0024 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0022 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0019 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0018 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0017 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0015 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0022 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0024 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0023 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0024 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0023 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0027 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0030 - acc: 0.9987
2450/5452 [============>.................] - ETA: 1s - loss: 0.0029 - acc: 0.9988
2550/5452 [=============>................] - ETA: 1s - loss: 0.0028 - acc: 0.9988
2650/5452 [=============>................] - ETA: 1s - loss: 0.0028 - acc: 0.9989
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0041 - acc: 0.9985
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0040 - acc: 0.9986
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0039 - acc: 0.9986
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0038 - acc: 0.9987
3150/5452 [================>.............] - ETA: 1s - loss: 0.0037 - acc: 0.9987
3250/5452 [================>.............] - ETA: 1s - loss: 0.0036 - acc: 0.9988
3350/5452 [=================>............] - ETA: 1s - loss: 0.0035 - acc: 0.9988
3450/5452 [=================>............] - ETA: 1s - loss: 0.0034 - acc: 0.9988
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0034 - acc: 0.9989
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0033 - acc: 0.9989
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0032 - acc: 0.9989
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0032 - acc: 0.9990
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0031 - acc: 0.9990
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0031 - acc: 0.9990
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0030 - acc: 0.9990
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0030 - acc: 0.9991
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0029 - acc: 0.9991
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0029 - acc: 0.9991
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9991
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 0.9991
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9992
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9992
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 0.9992
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9992
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993
5452/5452 [==============================] - 3s 622us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.3820 - val_acc: 0.9280

Epoch 00034: val_acc did not improve from 0.93400
Epoch 35/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0019 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0021 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0017 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0015 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0016 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0014 - acc: 1.0000
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0016 - acc: 1.0000
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2450/5452 [============>.................] - ETA: 1s - loss: 0.0014 - acc: 1.0000
2550/5452 [=============>................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2650/5452 [=============>................] - ETA: 1s - loss: 0.0014 - acc: 1.0000
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0014 - acc: 1.0000
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0015 - acc: 1.0000
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0020 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3450/5452 [=================>............] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0019 - acc: 0.9997
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0024 - acc: 0.9995
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0023 - acc: 0.9995
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0023 - acc: 0.9995
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0023 - acc: 0.9996
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0022 - acc: 0.9996
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0022 - acc: 0.9996
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0028 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0026 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9994
5452/5452 [==============================] - 3s 626us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.3853 - val_acc: 0.9280

Epoch 00035: val_acc did not improve from 0.93400
Epoch 36/200

  50/5452 [..............................] - ETA: 3s - loss: 8.2452e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0011 - acc: 1.0000    
 250/5452 [>.............................] - ETA: 3s - loss: 9.0868e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0061 - acc: 0.9971    
 450/5452 [=>............................] - ETA: 3s - loss: 0.0050 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 3s - loss: 0.0042 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0039 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0034 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0031 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0029 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0027 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0026 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0024 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0023 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0022 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0028 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0027 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0026 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0026 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0026 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0025 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 2s - loss: 0.0025 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0024 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0024 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0024 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0024 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0023 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0023 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0022 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0022 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0021 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0025 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0025 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0024 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0024 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0024 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0024 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0023 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0023 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0021 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0021 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0021 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0020 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0020 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0020 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5452/5452 [==============================] - 3s 620us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.3840 - val_acc: 0.9280

Epoch 00036: val_acc did not improve from 0.93400
Epoch 37/200

  50/5452 [..............................] - ETA: 3s - loss: 5.8540e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 5.8586e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 7.8746e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 9.0931e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 2s - loss: 0.0041 - acc: 0.9978    
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0035 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0031 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0030 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0029 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0027 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0025 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0025 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0024 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0023 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0022 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0021 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0020 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0019 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0019 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0018 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0018 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0017 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0021 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0020 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0021 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0021 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0021 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0022 - acc: 0.9990
3250/5452 [================>.............] - ETA: 1s - loss: 0.0022 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0021 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0021 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0021 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0022 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0022 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0022 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0021 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0021 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0021 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0021 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0020 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0020 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0020 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0020 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0018 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994
5452/5452 [==============================] - 3s 617us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.3832 - val_acc: 0.9280

Epoch 00037: val_acc did not improve from 0.93400
Epoch 38/200

  50/5452 [..............................] - ETA: 3s - loss: 5.5493e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 6.7224e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0016 - acc: 1.0000    
 350/5452 [>.............................] - ETA: 3s - loss: 0.0040 - acc: 0.9971
 450/5452 [=>............................] - ETA: 3s - loss: 0.0033 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0029 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0026 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0024 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0021 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0019 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0018 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0017 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0016 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0016 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0015 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0015 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0016 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0017 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0016 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0017 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0015 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0015 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0015 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0015 - acc: 0.9996
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3450/5452 [=================>............] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0015 - acc: 0.9997
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0015 - acc: 0.9997
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0015 - acc: 0.9997
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0015 - acc: 0.9998
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0014 - acc: 0.9998
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0015 - acc: 0.9998
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0016 - acc: 0.9996
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5350/5452 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5450/5452 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996
5452/5452 [==============================] - 3s 617us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.3833 - val_acc: 0.9280

Epoch 00038: val_acc did not improve from 0.93400
Epoch 39/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0012 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0013 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 0.0015 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 0.0013 - acc: 1.0000
 450/5452 [=>............................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0012 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0013 - acc: 1.0000
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0065 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0059 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0054 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0050 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0047 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0046 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0043 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0041 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0039 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0037 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0036 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0035 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0033 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0033 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0034 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0033 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0033 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0035 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0034 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0033 - acc: 0.9996
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0032 - acc: 0.9996
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0031 - acc: 0.9997
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0030 - acc: 0.9997
3150/5452 [================>.............] - ETA: 1s - loss: 0.0030 - acc: 0.9997
3250/5452 [================>.............] - ETA: 1s - loss: 0.0029 - acc: 0.9997
3350/5452 [=================>............] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3450/5452 [=================>............] - ETA: 1s - loss: 0.0029 - acc: 0.9997
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0028 - acc: 0.9997
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0027 - acc: 0.9997
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9997
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0026 - acc: 0.9997
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 0.9998
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9998
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0025 - acc: 0.9998
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 0.9998
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 0.9998
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 0.9998
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0024 - acc: 0.9998
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0024 - acc: 0.9998
5350/5452 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998
5450/5452 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9998
5452/5452 [==============================] - 3s 617us/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.3824 - val_acc: 0.9280

Epoch 00039: val_acc did not improve from 0.93400
Epoch 40/200

  50/5452 [..............................] - ETA: 3s - loss: 0.0016 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0010 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 8.5748e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 8.1096e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 8.0722e-04 - acc: 1.0000
 550/5452 [==>...........................] - ETA: 2s - loss: 8.4454e-04 - acc: 1.0000
 650/5452 [==>...........................] - ETA: 2s - loss: 8.5845e-04 - acc: 1.0000
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0019 - acc: 0.9987    
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0019 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0018 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0017 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0016 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0016 - acc: 0.9992
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0016 - acc: 0.9993
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0015 - acc: 0.9993
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0015 - acc: 0.9994
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0014 - acc: 0.9994
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0015 - acc: 0.9994
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0015 - acc: 0.9995
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0014 - acc: 0.9995
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0014 - acc: 0.9995
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0013 - acc: 0.9995
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0013 - acc: 0.9996
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0013 - acc: 0.9996
2450/5452 [============>.................] - ETA: 1s - loss: 0.0013 - acc: 0.9996
2550/5452 [=============>................] - ETA: 1s - loss: 0.0014 - acc: 0.9996
2650/5452 [=============>................] - ETA: 1s - loss: 0.0016 - acc: 0.9996
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0029 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0028 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0028 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0027 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0027 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0026 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0030 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0030 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0029 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0028 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0028 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0027 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0027 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0025 - acc: 0.9992
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0025 - acc: 0.9992
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0025 - acc: 0.9992
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0025 - acc: 0.9992
5350/5452 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993
5450/5452 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993
5452/5452 [==============================] - 3s 620us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.3815 - val_acc: 0.9260

Epoch 00040: val_acc did not improve from 0.93400
Epoch 41/200

  50/5452 [..............................] - ETA: 3s - loss: 6.8007e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 6.0991e-04 - acc: 1.0000
 250/5452 [>.............................] - ETA: 3s - loss: 7.6377e-04 - acc: 1.0000
 350/5452 [>.............................] - ETA: 3s - loss: 7.8905e-04 - acc: 1.0000
 450/5452 [=>............................] - ETA: 3s - loss: 0.0034 - acc: 0.9978    
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0029 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0025 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0023 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0021 - acc: 0.9988
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0020 - acc: 0.9989
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0019 - acc: 0.9990
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0017 - acc: 0.9991
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0026 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0025 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0024 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0023 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0022 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0021 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0020 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0020 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0019 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0019 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0018 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0018 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0017 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0017 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0018 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0020 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0019 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0019 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0019 - acc: 0.9994
3350/5452 [=================>............] - ETA: 1s - loss: 0.0018 - acc: 0.9994
3450/5452 [=================>............] - ETA: 1s - loss: 0.0018 - acc: 0.9994
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0018 - acc: 0.9994
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0018 - acc: 0.9995
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0018 - acc: 0.9995
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0023 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0023 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0023 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0023 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0022 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0022 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0022 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0022 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0021 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0021 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0021 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0021 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9994
5452/5452 [==============================] - 3s 619us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.3830 - val_acc: 0.9260

Epoch 00041: val_acc did not improve from 0.93400
Epoch 42/200

  50/5452 [..............................] - ETA: 3s - loss: 7.5833e-04 - acc: 1.0000
 150/5452 [..............................] - ETA: 3s - loss: 0.0269 - acc: 0.9933    
 250/5452 [>.............................] - ETA: 3s - loss: 0.0166 - acc: 0.9960
 350/5452 [>.............................] - ETA: 3s - loss: 0.0120 - acc: 0.9971
 450/5452 [=>............................] - ETA: 3s - loss: 0.0095 - acc: 0.9978
 550/5452 [==>...........................] - ETA: 2s - loss: 0.0080 - acc: 0.9982
 650/5452 [==>...........................] - ETA: 2s - loss: 0.0069 - acc: 0.9985
 750/5452 [===>..........................] - ETA: 2s - loss: 0.0061 - acc: 0.9987
 850/5452 [===>..........................] - ETA: 2s - loss: 0.0068 - acc: 0.9976
 950/5452 [====>.........................] - ETA: 2s - loss: 0.0062 - acc: 0.9979
1050/5452 [====>.........................] - ETA: 2s - loss: 0.0057 - acc: 0.9981
1150/5452 [=====>........................] - ETA: 2s - loss: 0.0052 - acc: 0.9983
1250/5452 [=====>........................] - ETA: 2s - loss: 0.0049 - acc: 0.9984
1350/5452 [======>.......................] - ETA: 2s - loss: 0.0046 - acc: 0.9985
1450/5452 [======>.......................] - ETA: 2s - loss: 0.0044 - acc: 0.9986
1550/5452 [=======>......................] - ETA: 2s - loss: 0.0041 - acc: 0.9987
1650/5452 [========>.....................] - ETA: 2s - loss: 0.0040 - acc: 0.9988
1750/5452 [========>.....................] - ETA: 2s - loss: 0.0038 - acc: 0.9989
1850/5452 [=========>....................] - ETA: 2s - loss: 0.0036 - acc: 0.9989
1950/5452 [=========>....................] - ETA: 2s - loss: 0.0038 - acc: 0.9990
2050/5452 [==========>...................] - ETA: 2s - loss: 0.0036 - acc: 0.9990
2150/5452 [==========>...................] - ETA: 1s - loss: 0.0035 - acc: 0.9991
2250/5452 [===========>..................] - ETA: 1s - loss: 0.0034 - acc: 0.9991
2350/5452 [===========>..................] - ETA: 1s - loss: 0.0033 - acc: 0.9991
2450/5452 [============>.................] - ETA: 1s - loss: 0.0032 - acc: 0.9992
2550/5452 [=============>................] - ETA: 1s - loss: 0.0031 - acc: 0.9992
2650/5452 [=============>................] - ETA: 1s - loss: 0.0030 - acc: 0.9992
2750/5452 [==============>...............] - ETA: 1s - loss: 0.0029 - acc: 0.9993
2850/5452 [==============>...............] - ETA: 1s - loss: 0.0029 - acc: 0.9993
2950/5452 [===============>..............] - ETA: 1s - loss: 0.0028 - acc: 0.9993
3050/5452 [===============>..............] - ETA: 1s - loss: 0.0027 - acc: 0.9993
3150/5452 [================>.............] - ETA: 1s - loss: 0.0027 - acc: 0.9994
3250/5452 [================>.............] - ETA: 1s - loss: 0.0029 - acc: 0.9991
3350/5452 [=================>............] - ETA: 1s - loss: 0.0028 - acc: 0.9991
3450/5452 [=================>............] - ETA: 1s - loss: 0.0027 - acc: 0.9991
3550/5452 [==================>...........] - ETA: 1s - loss: 0.0027 - acc: 0.9992
3650/5452 [===================>..........] - ETA: 1s - loss: 0.0027 - acc: 0.9992
3750/5452 [===================>..........] - ETA: 1s - loss: 0.0026 - acc: 0.9992
3850/5452 [====================>.........] - ETA: 0s - loss: 0.0026 - acc: 0.9992
3950/5452 [====================>.........] - ETA: 0s - loss: 0.0026 - acc: 0.9992
4050/5452 [=====================>........] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4150/5452 [=====================>........] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4250/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4350/5452 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 0.9993
4450/5452 [=======================>......] - ETA: 0s - loss: 0.0024 - acc: 0.9993
4550/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9993
4650/5452 [========================>.....] - ETA: 0s - loss: 0.0024 - acc: 0.9994
4750/5452 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 0.9994
4850/5452 [=========================>....] - ETA: 0s - loss: 0.0023 - acc: 0.9994
4950/5452 [==========================>...] - ETA: 0s - loss: 0.0023 - acc: 0.9994
5050/5452 [==========================>...] - ETA: 0s - loss: 0.0023 - acc: 0.9994
5150/5452 [===========================>..] - ETA: 0s - loss: 0.0024 - acc: 0.9994
5250/5452 [===========================>..] - ETA: 0s - loss: 0.0023 - acc: 0.9994
5350/5452 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994
5450/5452 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994
5452/5452 [==============================] - 3s 617us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.3848 - val_acc: 0.9260
Using TensorFlow backend.

Epoch 00042: val_acc did not improve from 0.93400
Epoch 00042: early stopping
>> TEST ...
Test Accuracy: 0.934
[[ 78   1   1   0   0   1]
 [  0  78   6   2   0   8]
 [  0   1  64   0   0   0]
 [  2   3   0 106   0   2]
 [  0   0   0   0   8   1]
 [  0   3   0   1   1 133]]
> training sub-category <abbreviatio>n ..
>> sub-category: abbr
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  abb.txt (16, 9600) (16,) 16
TEST ::  abb.txt (1, 9600) (1,) 1
TRAIN ::  exp.txt (70, 9600) (70,) 70
TEST ::  exp.txt (8, 9600) (8,) 8
x_train: (86, 9600)  - y_train: (86,) - train_questions: 86
x_test: (9, 9600)  - y_test: (9,) - test_questions: 9
x_train: (86, 32, 300, 1)  - y_train: (86, 2) - train_questions: 86
x_test: (9, 32, 300, 1)  - y_test: (9, 2) - test_questions: 9
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 2)            130         dropout_2[0][0]                  
==================================================================================================
Total params: 2,366,514
Trainable params: 2,366,514
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 86 samples, validate on 9 samples
Epoch 1/200

50/86 [================>.............] - ETA: 1s - loss: 0.7028 - acc: 0.4000
86/86 [==============================] - 2s 25ms/step - loss: 0.5176 - acc: 0.6163 - val_loss: 0.3217 - val_acc: 0.8889

Epoch 00001: val_acc improved from -inf to 0.88889, saving model to word2vec_abbr_model.h5
Epoch 2/200

50/86 [================>.............] - ETA: 0s - loss: 0.3017 - acc: 0.8400
86/86 [==============================] - 0s 900us/step - loss: 0.3868 - acc: 0.8140 - val_loss: 0.1387 - val_acc: 0.8889

Epoch 00002: val_acc did not improve from 0.88889
Epoch 3/200

50/86 [================>.............] - ETA: 0s - loss: 0.0988 - acc: 0.9800
86/86 [==============================] - 0s 892us/step - loss: 0.1659 - acc: 0.9535 - val_loss: 0.1506 - val_acc: 0.8889

Epoch 00003: val_acc did not improve from 0.88889
Epoch 4/200

50/86 [================>.............] - ETA: 0s - loss: 0.2189 - acc: 0.9200
86/86 [==============================] - 0s 836us/step - loss: 0.2088 - acc: 0.9302 - val_loss: 0.1200 - val_acc: 1.0000

Epoch 00004: val_acc improved from 0.88889 to 1.00000, saving model to word2vec_abbr_model.h5
Epoch 5/200

50/86 [================>.............] - ETA: 0s - loss: 0.1686 - acc: 0.9400
86/86 [==============================] - 0s 812us/step - loss: 0.1358 - acc: 0.9535 - val_loss: 0.1162 - val_acc: 0.8889

Epoch 00005: val_acc did not improve from 1.00000
Epoch 6/200

50/86 [================>.............] - ETA: 0s - loss: 0.0961 - acc: 1.0000
86/86 [==============================] - 0s 817us/step - loss: 0.1336 - acc: 0.9767 - val_loss: 0.2091 - val_acc: 0.8889

Epoch 00006: val_acc did not improve from 1.00000
Epoch 7/200

50/86 [================>.............] - ETA: 0s - loss: 0.1549 - acc: 0.9200
86/86 [==============================] - 0s 798us/step - loss: 0.1365 - acc: 0.9302 - val_loss: 0.1826 - val_acc: 0.8889

Epoch 00007: val_acc did not improve from 1.00000
Epoch 8/200

50/86 [================>.............] - ETA: 0s - loss: 0.0488 - acc: 0.9800
86/86 [==============================] - 0s 749us/step - loss: 0.0585 - acc: 0.9767 - val_loss: 0.1095 - val_acc: 0.8889

Epoch 00008: val_acc did not improve from 1.00000
Epoch 9/200

50/86 [================>.............] - ETA: 0s - loss: 0.0487 - acc: 1.0000
86/86 [==============================] - 0s 755us/step - loss: 0.0808 - acc: 0.9535 - val_loss: 0.0560 - val_acc: 1.0000

Epoch 00009: val_acc did not improve from 1.00000

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 10/200

50/86 [================>.............] - ETA: 0s - loss: 0.0352 - acc: 1.0000
86/86 [==============================] - 0s 702us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0520 - val_acc: 1.0000

Epoch 00010: val_acc did not improve from 1.00000
Epoch 11/200

50/86 [================>.............] - ETA: 0s - loss: 0.0453 - acc: 0.9800
86/86 [==============================] - 0s 709us/step - loss: 0.0343 - acc: 0.9884 - val_loss: 0.0516 - val_acc: 1.0000

Epoch 00011: val_acc did not improve from 1.00000
Epoch 12/200

50/86 [================>.............] - ETA: 0s - loss: 0.0098 - acc: 1.0000
86/86 [==============================] - 0s 709us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 1.0000

Epoch 00012: val_acc did not improve from 1.00000
Epoch 13/200

50/86 [================>.............] - ETA: 0s - loss: 0.0293 - acc: 1.0000
86/86 [==============================] - 0s 678us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000

Epoch 00013: val_acc did not improve from 1.00000
Epoch 14/200

50/86 [================>.............] - ETA: 0s - loss: 0.0207 - acc: 1.0000
86/86 [==============================] - 0s 696us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0612 - val_acc: 1.0000

Epoch 00014: val_acc did not improve from 1.00000

Epoch 00014: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 15/200

50/86 [================>.............] - ETA: 0s - loss: 0.0223 - acc: 1.0000
86/86 [==============================] - 0s 691us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 1.0000

Epoch 00015: val_acc did not improve from 1.00000
Epoch 16/200

50/86 [================>.............] - ETA: 0s - loss: 0.0549 - acc: 0.9800
86/86 [==============================] - 0s 686us/step - loss: 0.0349 - acc: 0.9884 - val_loss: 0.0656 - val_acc: 1.0000

Epoch 00016: val_acc did not improve from 1.00000
Epoch 17/200

50/86 [================>.............] - ETA: 0s - loss: 0.0101 - acc: 1.0000
86/86 [==============================] - 0s 687us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 1.0000

Epoch 00017: val_acc did not improve from 1.00000
Epoch 18/200

50/86 [================>.............] - ETA: 0s - loss: 0.0114 - acc: 1.0000
86/86 [==============================] - 0s 688us/step - loss: 0.0351 - acc: 0.9884 - val_loss: 0.0694 - val_acc: 1.0000

Epoch 00018: val_acc did not improve from 1.00000
Epoch 19/200

50/86 [================>.............] - ETA: 0s - loss: 0.0110 - acc: 1.0000
86/86 [==============================] - 0s 676us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 1.0000

Epoch 00019: val_acc did not improve from 1.00000

Epoch 00019: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 20/200

50/86 [================>.............] - ETA: 0s - loss: 0.0106 - acc: 1.0000
86/86 [==============================] - 0s 684us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000

Epoch 00020: val_acc did not improve from 1.00000
Epoch 21/200

50/86 [================>.............] - ETA: 0s - loss: 0.0075 - acc: 1.0000
86/86 [==============================] - 0s 688us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 1.0000

Epoch 00021: val_acc did not improve from 1.00000
Epoch 22/200

50/86 [================>.............] - ETA: 0s - loss: 0.0148 - acc: 1.0000
86/86 [==============================] - 0s 680us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 1.0000

Epoch 00022: val_acc did not improve from 1.00000
Epoch 23/200

50/86 [================>.............] - ETA: 0s - loss: 0.0126 - acc: 1.0000
86/86 [==============================] - 0s 710us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 1.0000

Epoch 00023: val_acc did not improve from 1.00000
Epoch 24/200

50/86 [================>.............] - ETA: 0s - loss: 0.0077 - acc: 1.0000
86/86 [==============================] - 0s 698us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 1.0000
Using TensorFlow backend.

Epoch 00024: val_acc did not improve from 1.00000
Epoch 00024: early stopping
>> TEST ...
Test Accuracy: 1.0
[[1 0]
 [0 8]]
> training sub-category <entit>y ..
>> sub-category: enty
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  dismed.txt (103, 9600) (103,) 103
TEST ::  dismed.txt (2, 9600) (2,) 2
TRAIN ::  animal.txt (112, 9600) (112,) 112
TEST ::  animal.txt (16, 9600) (16,) 16
TRAIN ::  plant.txt (13, 9600) (13,) 13
TEST ::  plant.txt (5, 9600) (5,) 5
TRAIN ::  currency.txt (4, 9600) (4,) 4
TEST ::  currency.txt (6, 9600) (6,) 6
TRAIN ::  product.txt (42, 9600) (42,) 42
TEST ::  product.txt (4, 9600) (4,) 4
TRAIN ::  word.txt (26, 9600) (26,) 26
TRAIN ::  cremat.txt (207, 9600) (207,) 207
TRAIN ::  letter.txt (9, 9600) (9,) 9
TRAIN ::  color.txt (40, 9600) (40,) 40
TEST ::  color.txt (10, 9600) (10,) 10
TRAIN ::  lang.txt (16, 9600) (16,) 16
TEST ::  lang.txt (2, 9600) (2,) 2
TRAIN ::  religion.txt (4, 9600) (4,) 4
TRAIN ::  termeq.txt (93, 9600) (93,) 93
TEST ::  termeq.txt (7, 9600) (7,) 7
TRAIN ::  food.txt (103, 9600) (103,) 103
TEST ::  food.txt (4, 9600) (4,) 4
TRAIN ::  symbol.txt (11, 9600) (11,) 11
TRAIN ::  substance.txt (41, 9600) (41,) 41
TEST ::  substance.txt (15, 9600) (15,) 15
TRAIN ::  body.txt (16, 9600) (16,) 16
TEST ::  body.txt (2, 9600) (2,) 2
TRAIN ::  veh.txt (27, 9600) (27,) 27
TEST ::  veh.txt (4, 9600) (4,) 4
TRAIN ::  instru.txt (10, 9600) (10,) 10
TEST ::  instru.txt (1, 9600) (1,) 1
TRAIN ::  event.txt (56, 9600) (56,) 56
TEST ::  event.txt (2, 9600) (2,) 2
TRAIN ::  sport.txt (62, 9600) (62,) 62
TEST ::  sport.txt (1, 9600) (1,) 1
TRAIN ::  techmeth.txt (38, 9600) (38,) 38
TEST ::  techmeth.txt (1, 9600) (1,) 1
TRAIN ::  other.txt (217, 9600) (217,) 217
TEST ::  other.txt (12, 9600) (12,) 12
x_train: (1250, 9600)  - y_train: (1250,) - train_questions: 1250
x_test: (94, 9600)  - y_test: (94,) - test_questions: 94
x_train: (1250, 32, 300, 1)  - y_train: (1250, 22) - train_questions: 1250
x_test: (94, 32, 300, 1)  - y_test: (94, 22) - test_questions: 94
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 22)           1430        dropout_2[0][0]                  
==================================================================================================
Total params: 2,367,814
Trainable params: 2,367,814
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 1250 samples, validate on 94 samples
Epoch 1/200

  50/1250 [>.............................] - ETA: 46s - loss: 3.1019 - acc: 0.0400
 150/1250 [==>...........................] - ETA: 14s - loss: 2.9772 - acc: 0.1200
 250/1250 [=====>........................] - ETA: 8s - loss: 2.9666 - acc: 0.1360 
 350/1250 [=======>......................] - ETA: 5s - loss: 2.8995 - acc: 0.1686
 450/1250 [=========>....................] - ETA: 4s - loss: 2.8291 - acc: 0.2000
 550/1250 [============>.................] - ETA: 2s - loss: 2.7747 - acc: 0.2127
 650/1250 [==============>...............] - ETA: 2s - loss: 2.7050 - acc: 0.2354
 750/1250 [=================>............] - ETA: 1s - loss: 2.6539 - acc: 0.2520
 850/1250 [===================>..........] - ETA: 1s - loss: 2.6296 - acc: 0.2588
 950/1250 [=====================>........] - ETA: 0s - loss: 2.6056 - acc: 0.2621
1050/1250 [========================>.....] - ETA: 0s - loss: 2.5745 - acc: 0.2743
1150/1250 [==========================>...] - ETA: 0s - loss: 2.5428 - acc: 0.2852
1250/1250 [==============================] - 3s 2ms/step - loss: 2.5124 - acc: 0.3008 - val_loss: 2.3942 - val_acc: 0.3404

Epoch 00001: val_acc improved from -inf to 0.34043, saving model to word2vec_enty_model.h5
Epoch 2/200

  50/1250 [>.............................] - ETA: 0s - loss: 2.0090 - acc: 0.4600
 150/1250 [==>...........................] - ETA: 0s - loss: 1.7534 - acc: 0.5400
 250/1250 [=====>........................] - ETA: 0s - loss: 1.7570 - acc: 0.5360
 350/1250 [=======>......................] - ETA: 0s - loss: 1.7701 - acc: 0.5343
 450/1250 [=========>....................] - ETA: 0s - loss: 1.7497 - acc: 0.5333
 550/1250 [============>.................] - ETA: 0s - loss: 1.7349 - acc: 0.5364
 650/1250 [==============>...............] - ETA: 0s - loss: 1.7024 - acc: 0.5477
 750/1250 [=================>............] - ETA: 0s - loss: 1.6616 - acc: 0.5613
 850/1250 [===================>..........] - ETA: 0s - loss: 1.6361 - acc: 0.5659
 950/1250 [=====================>........] - ETA: 0s - loss: 1.6547 - acc: 0.5568
1050/1250 [========================>.....] - ETA: 0s - loss: 1.6267 - acc: 0.5705
1150/1250 [==========================>...] - ETA: 0s - loss: 1.5938 - acc: 0.5817
1250/1250 [==============================] - 1s 617us/step - loss: 1.5808 - acc: 0.5832 - val_loss: 1.7566 - val_acc: 0.4574

Epoch 00002: val_acc improved from 0.34043 to 0.45745, saving model to word2vec_enty_model.h5
Epoch 3/200

  50/1250 [>.............................] - ETA: 0s - loss: 1.0381 - acc: 0.8000
 150/1250 [==>...........................] - ETA: 0s - loss: 1.1416 - acc: 0.7267
 250/1250 [=====>........................] - ETA: 0s - loss: 1.1495 - acc: 0.7280
 350/1250 [=======>......................] - ETA: 0s - loss: 1.0969 - acc: 0.7314
 450/1250 [=========>....................] - ETA: 0s - loss: 1.0663 - acc: 0.7444
 550/1250 [============>.................] - ETA: 0s - loss: 1.0429 - acc: 0.7564
 650/1250 [==============>...............] - ETA: 0s - loss: 1.0418 - acc: 0.7615
 750/1250 [=================>............] - ETA: 0s - loss: 1.0319 - acc: 0.7680
 850/1250 [===================>..........] - ETA: 0s - loss: 1.0171 - acc: 0.7659
 950/1250 [=====================>........] - ETA: 0s - loss: 1.0052 - acc: 0.7684
1050/1250 [========================>.....] - ETA: 0s - loss: 0.9792 - acc: 0.7743
1150/1250 [==========================>...] - ETA: 0s - loss: 0.9879 - acc: 0.7713
1250/1250 [==============================] - 1s 616us/step - loss: 0.9635 - acc: 0.7800 - val_loss: 1.4687 - val_acc: 0.6170

Epoch 00003: val_acc improved from 0.45745 to 0.61702, saving model to word2vec_enty_model.h5
Epoch 4/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.7949 - acc: 0.8400
 150/1250 [==>...........................] - ETA: 0s - loss: 0.7333 - acc: 0.8667
 250/1250 [=====>........................] - ETA: 0s - loss: 0.7694 - acc: 0.8560
 350/1250 [=======>......................] - ETA: 0s - loss: 0.7167 - acc: 0.8571
 450/1250 [=========>....................] - ETA: 0s - loss: 0.7164 - acc: 0.8533
 550/1250 [============>.................] - ETA: 0s - loss: 0.6917 - acc: 0.8582
 650/1250 [==============>...............] - ETA: 0s - loss: 0.6729 - acc: 0.8646
 750/1250 [=================>............] - ETA: 0s - loss: 0.6515 - acc: 0.8693
 850/1250 [===================>..........] - ETA: 0s - loss: 0.6410 - acc: 0.8765
 950/1250 [=====================>........] - ETA: 0s - loss: 0.6314 - acc: 0.8789
1050/1250 [========================>.....] - ETA: 0s - loss: 0.6205 - acc: 0.8810
1150/1250 [==========================>...] - ETA: 0s - loss: 0.6199 - acc: 0.8757
1250/1250 [==============================] - 1s 615us/step - loss: 0.6063 - acc: 0.8752 - val_loss: 1.3132 - val_acc: 0.6383

Epoch 00004: val_acc improved from 0.61702 to 0.63830, saving model to word2vec_enty_model.h5
Epoch 5/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.3089 - acc: 0.9400
 150/1250 [==>...........................] - ETA: 0s - loss: 0.4107 - acc: 0.9267
 250/1250 [=====>........................] - ETA: 0s - loss: 0.4055 - acc: 0.9280
 350/1250 [=======>......................] - ETA: 0s - loss: 0.4049 - acc: 0.9314
 450/1250 [=========>....................] - ETA: 0s - loss: 0.3910 - acc: 0.9333
 550/1250 [============>.................] - ETA: 0s - loss: 0.3900 - acc: 0.9309
 650/1250 [==============>...............] - ETA: 0s - loss: 0.3838 - acc: 0.9354
 750/1250 [=================>............] - ETA: 0s - loss: 0.3743 - acc: 0.9387
 850/1250 [===================>..........] - ETA: 0s - loss: 0.3670 - acc: 0.9400
 950/1250 [=====================>........] - ETA: 0s - loss: 0.3617 - acc: 0.9432
1050/1250 [========================>.....] - ETA: 0s - loss: 0.3541 - acc: 0.9448
1150/1250 [==========================>...] - ETA: 0s - loss: 0.3462 - acc: 0.9470
1250/1250 [==============================] - 1s 614us/step - loss: 0.3524 - acc: 0.9440 - val_loss: 1.1374 - val_acc: 0.6809

Epoch 00005: val_acc improved from 0.63830 to 0.68085, saving model to word2vec_enty_model.h5
Epoch 6/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.1321 - acc: 0.9800
 150/1250 [==>...........................] - ETA: 0s - loss: 0.2115 - acc: 0.9867
 250/1250 [=====>........................] - ETA: 0s - loss: 0.2359 - acc: 0.9840
 350/1250 [=======>......................] - ETA: 0s - loss: 0.2591 - acc: 0.9743
 450/1250 [=========>....................] - ETA: 0s - loss: 0.2654 - acc: 0.9711
 550/1250 [============>.................] - ETA: 0s - loss: 0.2592 - acc: 0.9691
 650/1250 [==============>...............] - ETA: 0s - loss: 0.2593 - acc: 0.9692
 750/1250 [=================>............] - ETA: 0s - loss: 0.2659 - acc: 0.9667
 850/1250 [===================>..........] - ETA: 0s - loss: 0.2669 - acc: 0.9659
 950/1250 [=====================>........] - ETA: 0s - loss: 0.2629 - acc: 0.9653
1050/1250 [========================>.....] - ETA: 0s - loss: 0.2544 - acc: 0.9676
1150/1250 [==========================>...] - ETA: 0s - loss: 0.2494 - acc: 0.9687
1250/1250 [==============================] - 1s 617us/step - loss: 0.2515 - acc: 0.9688 - val_loss: 1.0857 - val_acc: 0.7234

Epoch 00006: val_acc improved from 0.68085 to 0.72340, saving model to word2vec_enty_model.h5
Epoch 7/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.1023 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.2580 - acc: 0.9600
 250/1250 [=====>........................] - ETA: 0s - loss: 0.2248 - acc: 0.9560
 350/1250 [=======>......................] - ETA: 0s - loss: 0.2119 - acc: 0.9629
 450/1250 [=========>....................] - ETA: 0s - loss: 0.2094 - acc: 0.9644
 550/1250 [============>.................] - ETA: 0s - loss: 0.2078 - acc: 0.9636
 650/1250 [==============>...............] - ETA: 0s - loss: 0.1987 - acc: 0.9646
 750/1250 [=================>............] - ETA: 0s - loss: 0.1985 - acc: 0.9667
 850/1250 [===================>..........] - ETA: 0s - loss: 0.1909 - acc: 0.9706
 950/1250 [=====================>........] - ETA: 0s - loss: 0.1874 - acc: 0.9726
1050/1250 [========================>.....] - ETA: 0s - loss: 0.1847 - acc: 0.9733
1150/1250 [==========================>...] - ETA: 0s - loss: 0.1828 - acc: 0.9739
1250/1250 [==============================] - 1s 617us/step - loss: 0.1781 - acc: 0.9760 - val_loss: 1.0922 - val_acc: 0.6915

Epoch 00007: val_acc did not improve from 0.72340
Epoch 8/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.1659 - acc: 0.9600
 150/1250 [==>...........................] - ETA: 0s - loss: 0.1077 - acc: 0.9867
 250/1250 [=====>........................] - ETA: 0s - loss: 0.1099 - acc: 0.9880
 350/1250 [=======>......................] - ETA: 0s - loss: 0.1212 - acc: 0.9829
 450/1250 [=========>....................] - ETA: 0s - loss: 0.1167 - acc: 0.9844
 550/1250 [============>.................] - ETA: 0s - loss: 0.1189 - acc: 0.9818
 650/1250 [==============>...............] - ETA: 0s - loss: 0.1269 - acc: 0.9785
 750/1250 [=================>............] - ETA: 0s - loss: 0.1252 - acc: 0.9813
 850/1250 [===================>..........] - ETA: 0s - loss: 0.1230 - acc: 0.9835
 950/1250 [=====================>........] - ETA: 0s - loss: 0.1240 - acc: 0.9832
1050/1250 [========================>.....] - ETA: 0s - loss: 0.1260 - acc: 0.9829
1150/1250 [==========================>...] - ETA: 0s - loss: 0.1234 - acc: 0.9843
1250/1250 [==============================] - 1s 615us/step - loss: 0.1217 - acc: 0.9856 - val_loss: 1.0939 - val_acc: 0.7128

Epoch 00008: val_acc did not improve from 0.72340
Epoch 9/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0713 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.1085 - acc: 0.9933
 250/1250 [=====>........................] - ETA: 0s - loss: 0.1080 - acc: 0.9920
 350/1250 [=======>......................] - ETA: 0s - loss: 0.1097 - acc: 0.9943
 450/1250 [=========>....................] - ETA: 0s - loss: 0.1036 - acc: 0.9933
 550/1250 [============>.................] - ETA: 0s - loss: 0.1032 - acc: 0.9927
 650/1250 [==============>...............] - ETA: 0s - loss: 0.1034 - acc: 0.9923
 750/1250 [=================>............] - ETA: 0s - loss: 0.1023 - acc: 0.9920
 850/1250 [===================>..........] - ETA: 0s - loss: 0.1066 - acc: 0.9918
 950/1250 [=====================>........] - ETA: 0s - loss: 0.1089 - acc: 0.9916
1050/1250 [========================>.....] - ETA: 0s - loss: 0.1051 - acc: 0.9924
1150/1250 [==========================>...] - ETA: 0s - loss: 0.1033 - acc: 0.9922
1250/1250 [==============================] - 1s 615us/step - loss: 0.1069 - acc: 0.9912 - val_loss: 0.9082 - val_acc: 0.7553

Epoch 00009: val_acc improved from 0.72340 to 0.75532, saving model to word2vec_enty_model.h5
Epoch 10/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0733 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0728 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0895 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0823 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0840 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0836 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0827 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0786 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0773 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0762 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0766 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0834 - acc: 0.9957
1250/1250 [==============================] - 1s 617us/step - loss: 0.0832 - acc: 0.9952 - val_loss: 0.8833 - val_acc: 0.7553

Epoch 00010: val_acc did not improve from 0.75532
Epoch 11/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0511 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0850 - acc: 0.9933
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0875 - acc: 0.9960
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0801 - acc: 0.9971
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0798 - acc: 0.9978
 550/1250 [============>.................] - ETA: 0s - loss: 0.0766 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0749 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0730 - acc: 0.9973
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0740 - acc: 0.9965
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0749 - acc: 0.9958
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0729 - acc: 0.9962
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0720 - acc: 0.9965
1250/1250 [==============================] - 1s 616us/step - loss: 0.0725 - acc: 0.9968 - val_loss: 0.9842 - val_acc: 0.7766

Epoch 00011: val_acc improved from 0.75532 to 0.77660, saving model to word2vec_enty_model.h5
Epoch 12/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0648 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0610 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0631 - acc: 0.9960
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0608 - acc: 0.9971
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0617 - acc: 0.9956
 550/1250 [============>.................] - ETA: 0s - loss: 0.0629 - acc: 0.9964
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0632 - acc: 0.9954
 750/1250 [=================>............] - ETA: 0s - loss: 0.0614 - acc: 0.9960
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0610 - acc: 0.9965
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0588 - acc: 0.9968
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0583 - acc: 0.9962
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0589 - acc: 0.9957
1250/1250 [==============================] - 1s 618us/step - loss: 0.0600 - acc: 0.9960 - val_loss: 0.9541 - val_acc: 0.7766

Epoch 00012: val_acc improved from 0.77660 to 0.77660, saving model to word2vec_enty_model.h5
Epoch 13/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0386 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0438 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0455 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0411 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0420 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0451 - acc: 0.9964
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0450 - acc: 0.9969
 750/1250 [=================>............] - ETA: 0s - loss: 0.0435 - acc: 0.9973
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0441 - acc: 0.9976
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0451 - acc: 0.9979
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0456 - acc: 0.9981
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0463 - acc: 0.9983
1250/1250 [==============================] - 1s 616us/step - loss: 0.0457 - acc: 0.9984 - val_loss: 0.9347 - val_acc: 0.7766

Epoch 00013: val_acc did not improve from 0.77660
Epoch 14/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0534 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0398 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0403 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0415 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0374 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0378 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0409 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0398 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0437 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0454 - acc: 0.9979
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0443 - acc: 0.9981
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0447 - acc: 0.9983
1250/1250 [==============================] - 1s 617us/step - loss: 0.0466 - acc: 0.9984 - val_loss: 0.9440 - val_acc: 0.7979

Epoch 00014: val_acc improved from 0.77660 to 0.79787, saving model to word2vec_enty_model.h5
Epoch 15/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0639 - acc: 0.9800
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0368 - acc: 0.9933
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0356 - acc: 0.9960
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0339 - acc: 0.9971
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0333 - acc: 0.9978
 550/1250 [============>.................] - ETA: 0s - loss: 0.0347 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0340 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0333 - acc: 0.9987
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0342 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0342 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0346 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0359 - acc: 0.9983
1250/1250 [==============================] - 1s 616us/step - loss: 0.0357 - acc: 0.9984 - val_loss: 0.9141 - val_acc: 0.7660

Epoch 00015: val_acc did not improve from 0.79787
Epoch 16/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0315 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0397 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0388 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0344 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0331 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0355 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0338 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0340 - acc: 0.9987
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0334 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0351 - acc: 0.9979
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0355 - acc: 0.9981
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0348 - acc: 0.9983
1250/1250 [==============================] - 1s 617us/step - loss: 0.0346 - acc: 0.9984 - val_loss: 0.9622 - val_acc: 0.7872

Epoch 00016: val_acc did not improve from 0.79787
Epoch 17/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0448 - acc: 0.9800
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0375 - acc: 0.9933
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0381 - acc: 0.9960
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0338 - acc: 0.9971
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0340 - acc: 0.9978
 550/1250 [============>.................] - ETA: 0s - loss: 0.0338 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0316 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0307 - acc: 0.9987
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0300 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0293 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0287 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0284 - acc: 0.9991
1250/1250 [==============================] - 1s 617us/step - loss: 0.0289 - acc: 0.9992 - val_loss: 1.0296 - val_acc: 0.7553

Epoch 00017: val_acc did not improve from 0.79787
Epoch 18/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0240 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0206 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0206 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0235 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0257 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0251 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0261 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0257 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0272 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0267 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0268 - acc: 1.0000
1250/1250 [==============================] - 1s 619us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 1.0590 - val_acc: 0.7553

Epoch 00018: val_acc did not improve from 0.79787
Epoch 19/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0229 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0185 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0207 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0231 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0233 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0243 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0258 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0262 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0256 - acc: 0.9991
1250/1250 [==============================] - 1s 618us/step - loss: 0.0271 - acc: 0.9984 - val_loss: 1.0020 - val_acc: 0.7553

Epoch 00019: val_acc did not improve from 0.79787

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 20/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0224 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0211 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0211 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0230 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0225 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0239 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0256 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0253 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0251 - acc: 1.0000
1250/1250 [==============================] - 1s 616us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 1.0153 - val_acc: 0.7447

Epoch 00020: val_acc did not improve from 0.79787
Epoch 21/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0153 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0247 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0253 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0250 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0265 - acc: 0.9978
 550/1250 [============>.................] - ETA: 0s - loss: 0.0275 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0266 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0260 - acc: 0.9987
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0252 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0253 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0247 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0246 - acc: 0.9991
1250/1250 [==============================] - 1s 615us/step - loss: 0.0244 - acc: 0.9992 - val_loss: 0.9962 - val_acc: 0.7553

Epoch 00021: val_acc did not improve from 0.79787
Epoch 22/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0152 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0187 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0213 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0231 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0218 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0219 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0224 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0226 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0227 - acc: 1.0000
1250/1250 [==============================] - 1s 615us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.7660

Epoch 00022: val_acc did not improve from 0.79787
Epoch 23/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0147 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0190 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0196 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0225 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0218 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0229 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0225 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0224 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0228 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0227 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0224 - acc: 1.0000
1250/1250 [==============================] - 1s 613us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.0314 - val_acc: 0.7553

Epoch 00023: val_acc did not improve from 0.79787
Epoch 24/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0280 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0242 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0271 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0244 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0255 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0242 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0235 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0225 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0229 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0242 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0238 - acc: 1.0000
1250/1250 [==============================] - 1s 615us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.7553

Epoch 00024: val_acc did not improve from 0.79787

Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 25/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0120 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0194 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0212 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0199 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0191 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0214 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0207 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0209 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0217 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0212 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0219 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0227 - acc: 1.0000
1250/1250 [==============================] - 1s 616us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.0194 - val_acc: 0.7553

Epoch 00025: val_acc did not improve from 0.79787
Epoch 26/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0231 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0188 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0274 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0256 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0238 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0221 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0224 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0214 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0212 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0207 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0208 - acc: 1.0000
1250/1250 [==============================] - 1s 613us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.0190 - val_acc: 0.7660

Epoch 00026: val_acc did not improve from 0.79787
Epoch 27/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0253 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0262 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0231 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0223 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0217 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0238 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0244 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0241 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0236 - acc: 0.9991
1250/1250 [==============================] - 1s 610us/step - loss: 0.0228 - acc: 0.9992 - val_loss: 1.0335 - val_acc: 0.7553

Epoch 00027: val_acc did not improve from 0.79787
Epoch 28/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0194 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0178 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0191 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0243 - acc: 0.9971
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0225 - acc: 0.9978
 550/1250 [============>.................] - ETA: 0s - loss: 0.0230 - acc: 0.9982
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0231 - acc: 0.9985
 750/1250 [=================>............] - ETA: 0s - loss: 0.0231 - acc: 0.9987
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0225 - acc: 0.9988
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0242 - acc: 0.9989
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0240 - acc: 0.9990
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0234 - acc: 0.9991
1250/1250 [==============================] - 1s 612us/step - loss: 0.0226 - acc: 0.9992 - val_loss: 1.0277 - val_acc: 0.7553

Epoch 00028: val_acc did not improve from 0.79787
Epoch 29/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0167 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0200 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0200 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0196 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0196 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0198 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0203 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0213 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0215 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0218 - acc: 1.0000
1250/1250 [==============================] - 1s 611us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.0232 - val_acc: 0.7553

Epoch 00029: val_acc did not improve from 0.79787

Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 30/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0167 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0215 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0195 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0202 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0204 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0197 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0191 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0201 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0212 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0210 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0205 - acc: 1.0000
1250/1250 [==============================] - 1s 611us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.0230 - val_acc: 0.7553

Epoch 00030: val_acc did not improve from 0.79787
Epoch 31/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0256 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0191 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0178 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0171 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0174 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0175 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0176 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0178 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0178 - acc: 1.0000
1250/1250 [==============================] - 1s 610us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 1.0230 - val_acc: 0.7553

Epoch 00031: val_acc did not improve from 0.79787
Epoch 32/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0164 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0160 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0174 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0183 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0171 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0172 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0177 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0179 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0176 - acc: 1.0000
1250/1250 [==============================] - 1s 611us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.0224 - val_acc: 0.7660

Epoch 00032: val_acc did not improve from 0.79787
Epoch 33/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0148 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0123 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0184 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0209 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0202 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0219 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0226 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0218 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0214 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0211 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0208 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0206 - acc: 1.0000
1250/1250 [==============================] - 1s 614us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.0213 - val_acc: 0.7660

Epoch 00033: val_acc did not improve from 0.79787
Epoch 34/200

  50/1250 [>.............................] - ETA: 0s - loss: 0.0141 - acc: 1.0000
 150/1250 [==>...........................] - ETA: 0s - loss: 0.0165 - acc: 1.0000
 250/1250 [=====>........................] - ETA: 0s - loss: 0.0178 - acc: 1.0000
 350/1250 [=======>......................] - ETA: 0s - loss: 0.0168 - acc: 1.0000
 450/1250 [=========>....................] - ETA: 0s - loss: 0.0217 - acc: 1.0000
 550/1250 [============>.................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 650/1250 [==============>...............] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 750/1250 [=================>............] - ETA: 0s - loss: 0.0198 - acc: 1.0000
 850/1250 [===================>..........] - ETA: 0s - loss: 0.0200 - acc: 1.0000
 950/1250 [=====================>........] - ETA: 0s - loss: 0.0193 - acc: 1.0000
1050/1250 [========================>.....] - ETA: 0s - loss: 0.0190 - acc: 1.0000
1150/1250 [==========================>...] - ETA: 0s - loss: 0.0199 - acc: 1.0000
1250/1250 [==============================] - 1s 616us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.0212 - val_acc: 0.7660
Using TensorFlow backend.

Epoch 00034: val_acc did not improve from 0.79787
Epoch 00034: early stopping
>> TEST ...
Test Accuracy: 0.7978723404255319
[[ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]
 [ 0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  5  0  0  0  0  0  0  1  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  0  0  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0]
 [ 0  1  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  1  1  0  0  1  8  0  0  0  0  0  0  4]
 [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]
 [ 0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  1  1  8]]
> training sub-category <description> ..
>> sub-category: desc
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  def.txt (421, 9600) (421,) 421
TEST ::  def.txt (123, 9600) (123,) 123
TRAIN ::  manner.txt (276, 9600) (276,) 276
TEST ::  manner.txt (2, 9600) (2,) 2
TRAIN ::  desc.txt (274, 9600) (274,) 274
TEST ::  desc.txt (7, 9600) (7,) 7
TRAIN ::  reason.txt (191, 9600) (191,) 191
TEST ::  reason.txt (6, 9600) (6,) 6
x_train: (1162, 9600)  - y_train: (1162,) - train_questions: 1162
x_test: (138, 9600)  - y_test: (138,) - test_questions: 138
x_train: (1162, 32, 300, 1)  - y_train: (1162, 4) - train_questions: 1162
x_test: (138, 32, 300, 1)  - y_test: (138, 4) - test_questions: 138
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 4)            260         dropout_2[0][0]                  
==================================================================================================
Total params: 2,366,644
Trainable params: 2,366,644
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 1162 samples, validate on 138 samples
Epoch 1/200

  50/1162 [>.............................] - ETA: 44s - loss: 1.3818 - acc: 0.2200
 150/1162 [==>...........................] - ETA: 14s - loss: 1.3365 - acc: 0.3267
 250/1162 [=====>........................] - ETA: 7s - loss: 1.2498 - acc: 0.4200 
 350/1162 [========>.....................] - ETA: 5s - loss: 1.1468 - acc: 0.4743
 450/1162 [==========>...................] - ETA: 3s - loss: 1.0877 - acc: 0.5178
 550/1162 [=============>................] - ETA: 2s - loss: 1.0361 - acc: 0.5527
 650/1162 [===============>..............] - ETA: 1s - loss: 0.9778 - acc: 0.5800
 750/1162 [==================>...........] - ETA: 1s - loss: 0.9405 - acc: 0.5960
 850/1162 [====================>.........] - ETA: 0s - loss: 0.8932 - acc: 0.6165
 950/1162 [=======================>......] - ETA: 0s - loss: 0.8645 - acc: 0.6358
1050/1162 [==========================>...] - ETA: 0s - loss: 0.8280 - acc: 0.6524
1150/1162 [============================>.] - ETA: 0s - loss: 0.8041 - acc: 0.6661
1162/1162 [==============================] - 3s 3ms/step - loss: 0.8031 - acc: 0.6670 - val_loss: 0.1032 - val_acc: 1.0000

Epoch 00001: val_acc improved from -inf to 1.00000, saving model to word2vec_desc_model.h5
Epoch 2/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.4178 - acc: 0.9000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.3920 - acc: 0.8667
 250/1162 [=====>........................] - ETA: 0s - loss: 0.3343 - acc: 0.8800
 350/1162 [========>.....................] - ETA: 0s - loss: 0.3334 - acc: 0.8829
 450/1162 [==========>...................] - ETA: 0s - loss: 0.3005 - acc: 0.8933
 550/1162 [=============>................] - ETA: 0s - loss: 0.2794 - acc: 0.9018
 650/1162 [===============>..............] - ETA: 0s - loss: 0.2724 - acc: 0.9046
 750/1162 [==================>...........] - ETA: 0s - loss: 0.2735 - acc: 0.9040
 850/1162 [====================>.........] - ETA: 0s - loss: 0.2690 - acc: 0.9071
 950/1162 [=======================>......] - ETA: 0s - loss: 0.2579 - acc: 0.9095
1050/1162 [==========================>...] - ETA: 0s - loss: 0.2527 - acc: 0.9133
1150/1162 [============================>.] - ETA: 0s - loss: 0.2462 - acc: 0.9165
1162/1162 [==============================] - 1s 633us/step - loss: 0.2441 - acc: 0.9174 - val_loss: 0.0473 - val_acc: 0.9710

Epoch 00002: val_acc did not improve from 1.00000
Epoch 3/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.1061 - acc: 0.9800
 150/1162 [==>...........................] - ETA: 0s - loss: 0.1019 - acc: 0.9800
 250/1162 [=====>........................] - ETA: 0s - loss: 0.1156 - acc: 0.9720
 350/1162 [========>.....................] - ETA: 0s - loss: 0.1137 - acc: 0.9714
 450/1162 [==========>...................] - ETA: 0s - loss: 0.1114 - acc: 0.9711
 550/1162 [=============>................] - ETA: 0s - loss: 0.1004 - acc: 0.9764
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0940 - acc: 0.9785
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0939 - acc: 0.9787
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0895 - acc: 0.9800
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0845 - acc: 0.9821
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0863 - acc: 0.9819
1150/1162 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9817
1162/1162 [==============================] - 1s 628us/step - loss: 0.0871 - acc: 0.9819 - val_loss: 0.0166 - val_acc: 1.0000

Epoch 00003: val_acc did not improve from 1.00000
Epoch 4/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0243 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0214 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0198 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0209 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0259 - acc: 0.9978
 550/1162 [=============>................] - ETA: 0s - loss: 0.0252 - acc: 0.9982
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0242 - acc: 0.9985
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0347 - acc: 0.9960
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0351 - acc: 0.9953
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0341 - acc: 0.9958
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0326 - acc: 0.9962
1150/1162 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9965
1162/1162 [==============================] - 1s 627us/step - loss: 0.0314 - acc: 0.9966 - val_loss: 0.0080 - val_acc: 1.0000

Epoch 00004: val_acc did not improve from 1.00000
Epoch 5/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0142 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0157 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0158 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0144 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0136 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0137 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0241 - acc: 0.9985
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0220 - acc: 0.9987
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0209 - acc: 0.9988
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0202 - acc: 0.9989
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0197 - acc: 0.9990
1150/1162 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9991
1162/1162 [==============================] - 1s 627us/step - loss: 0.0191 - acc: 0.9991 - val_loss: 0.0079 - val_acc: 1.0000

Epoch 00005: val_acc did not improve from 1.00000
Epoch 6/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0081 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0099 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0095 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0103 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0099 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0096 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0100 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9991
1162/1162 [==============================] - 1s 629us/step - loss: 0.0147 - acc: 0.9991 - val_loss: 0.0185 - val_acc: 0.9928

Epoch 00006: val_acc did not improve from 1.00000

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 7/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0082 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0081 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0080 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0080 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0076 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0073 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0072 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9991
1162/1162 [==============================] - 1s 631us/step - loss: 0.0125 - acc: 0.9991 - val_loss: 0.0141 - val_acc: 0.9928

Epoch 00007: val_acc did not improve from 1.00000
Epoch 8/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0111 - acc: 0.9989
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0108 - acc: 0.9990
1150/1162 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9991
1162/1162 [==============================] - 1s 631us/step - loss: 0.0104 - acc: 0.9991 - val_loss: 0.0133 - val_acc: 0.9928

Epoch 00008: val_acc did not improve from 1.00000
Epoch 9/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0102 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0084 - acc: 0.9989
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0081 - acc: 0.9990
1150/1162 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9991
1162/1162 [==============================] - 1s 636us/step - loss: 0.0084 - acc: 0.9991 - val_loss: 0.0116 - val_acc: 0.9928

Epoch 00009: val_acc did not improve from 1.00000
Epoch 10/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0113 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0077 - acc: 0.9989
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0076 - acc: 0.9990
1150/1162 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9991
1162/1162 [==============================] - 1s 633us/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.0139 - val_acc: 0.9928

Epoch 00010: val_acc did not improve from 1.00000
Epoch 11/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0050 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0049 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 1.0000
1162/1162 [==============================] - 1s 635us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9928

Epoch 00011: val_acc did not improve from 1.00000

Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 12/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0049 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0050 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9991
1162/1162 [==============================] - 1s 637us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0122 - val_acc: 0.9928

Epoch 00012: val_acc did not improve from 1.00000
Epoch 13/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0115 - acc: 0.9971
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0102 - acc: 0.9978
 550/1162 [=============>................] - ETA: 0s - loss: 0.0094 - acc: 0.9982
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0086 - acc: 0.9985
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0085 - acc: 0.9987
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0081 - acc: 0.9988
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0077 - acc: 0.9989
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0074 - acc: 0.9990
1150/1162 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9991
1162/1162 [==============================] - 1s 638us/step - loss: 0.0073 - acc: 0.9991 - val_loss: 0.0120 - val_acc: 0.9928

Epoch 00013: val_acc did not improve from 1.00000
Epoch 14/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0053 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 1.0000
1162/1162 [==============================] - 1s 637us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9928

Epoch 00014: val_acc did not improve from 1.00000
Epoch 15/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0055 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0054 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 1.0000
1162/1162 [==============================] - 1s 636us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0116 - val_acc: 0.9928

Epoch 00015: val_acc did not improve from 1.00000
Epoch 16/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0054 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0053 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 1.0000
1162/1162 [==============================] - 1s 635us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9928

Epoch 00016: val_acc did not improve from 1.00000

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 17/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0056 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0058 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 1.0000
1162/1162 [==============================] - 1s 636us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9928

Epoch 00017: val_acc did not improve from 1.00000
Epoch 18/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0048 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0048 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 1.0000
1162/1162 [==============================] - 1s 636us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9928

Epoch 00018: val_acc did not improve from 1.00000
Epoch 19/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0045 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 1.0000
1162/1162 [==============================] - 1s 636us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9928

Epoch 00019: val_acc did not improve from 1.00000
Epoch 20/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0054 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 1.0000
1162/1162 [==============================] - 1s 639us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9928

Epoch 00020: val_acc did not improve from 1.00000
Epoch 21/200

  50/1162 [>.............................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 150/1162 [==>...........................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 250/1162 [=====>........................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 350/1162 [========>.....................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 450/1162 [==========>...................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 550/1162 [=============>................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 650/1162 [===============>..............] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 750/1162 [==================>...........] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 850/1162 [====================>.........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 950/1162 [=======================>......] - ETA: 0s - loss: 0.0057 - acc: 1.0000
1050/1162 [==========================>...] - ETA: 0s - loss: 0.0057 - acc: 1.0000
1150/1162 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 1.0000
1162/1162 [==============================] - 1s 635us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9928
Using TensorFlow backend.

Epoch 00021: val_acc did not improve from 1.00000
Epoch 00021: early stopping
>> TEST ...
Test Accuracy: 1.0
[[123   0   0   0]
 [  0   2   0   0]
 [  0   0   7   0]
 [  0   0   0   6]]
> training sub-category <human> ..
>> sub-category: hum
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  ind.txt (962, 9600) (962,) 962
TRAIN ::  title.txt (25, 9600) (25,) 25
TRAIN ::  gr.txt (189, 9600) (189,) 189
TEST ::  gr.txt (6, 9600) (6,) 6
TRAIN ::  desc.txt (47, 9600) (47,) 47
TEST ::  desc.txt (3, 9600) (3,) 3
x_train: (1223, 9600)  - y_train: (1223,) - train_questions: 1223
x_test: (9, 9600)  - y_test: (9,) - test_questions: 9
x_train: (1223, 32, 300, 1)  - y_train: (1223, 4) - train_questions: 1223
x_test: (9, 32, 300, 1)  - y_test: (9, 4) - test_questions: 9
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 4)            260         dropout_2[0][0]                  
==================================================================================================
Total params: 2,366,644
Trainable params: 2,366,644
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 1223 samples, validate on 9 samples
Epoch 1/200

  50/1223 [>.............................] - ETA: 46s - loss: 1.3643 - acc: 0.4600
 150/1223 [==>...........................] - ETA: 14s - loss: 0.9066 - acc: 0.6867
 250/1223 [=====>........................] - ETA: 8s - loss: 0.9043 - acc: 0.7280 
 350/1223 [=======>......................] - ETA: 5s - loss: 0.8576 - acc: 0.7486
 450/1223 [==========>...................] - ETA: 3s - loss: 0.8754 - acc: 0.7400
 550/1223 [============>.................] - ETA: 2s - loss: 0.8476 - acc: 0.7327
 650/1223 [==============>...............] - ETA: 2s - loss: 0.8369 - acc: 0.7277
 750/1223 [=================>............] - ETA: 1s - loss: 0.7912 - acc: 0.7440
 850/1223 [===================>..........] - ETA: 1s - loss: 0.7669 - acc: 0.7518
 950/1223 [======================>.......] - ETA: 0s - loss: 0.7384 - acc: 0.7611
1050/1223 [========================>.....] - ETA: 0s - loss: 0.7145 - acc: 0.7686
1150/1223 [===========================>..] - ETA: 0s - loss: 0.7003 - acc: 0.7713
1223/1223 [==============================] - 3s 2ms/step - loss: 0.6869 - acc: 0.7768 - val_loss: 0.7969 - val_acc: 0.5556

Epoch 00001: val_acc improved from -inf to 0.55556, saving model to word2vec_hum_model.h5
Epoch 2/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.3656 - acc: 0.8800
 150/1223 [==>...........................] - ETA: 0s - loss: 0.4418 - acc: 0.8333
 250/1223 [=====>........................] - ETA: 0s - loss: 0.4272 - acc: 0.8400
 350/1223 [=======>......................] - ETA: 0s - loss: 0.3828 - acc: 0.8571
 450/1223 [==========>...................] - ETA: 0s - loss: 0.3518 - acc: 0.8689
 550/1223 [============>.................] - ETA: 0s - loss: 0.3526 - acc: 0.8727
 650/1223 [==============>...............] - ETA: 0s - loss: 0.3436 - acc: 0.8769
 750/1223 [=================>............] - ETA: 0s - loss: 0.3407 - acc: 0.8813
 850/1223 [===================>..........] - ETA: 0s - loss: 0.3416 - acc: 0.8847
 950/1223 [======================>.......] - ETA: 0s - loss: 0.3364 - acc: 0.8863
1050/1223 [========================>.....] - ETA: 0s - loss: 0.3242 - acc: 0.8914
1150/1223 [===========================>..] - ETA: 0s - loss: 0.3106 - acc: 0.8974
1223/1223 [==============================] - 1s 613us/step - loss: 0.3031 - acc: 0.9011 - val_loss: 0.3480 - val_acc: 0.8889

Epoch 00002: val_acc improved from 0.55556 to 0.88889, saving model to word2vec_hum_model.h5
Epoch 3/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0917 - acc: 0.9800
 150/1223 [==>...........................] - ETA: 0s - loss: 0.1252 - acc: 0.9733
 250/1223 [=====>........................] - ETA: 0s - loss: 0.1097 - acc: 0.9760
 350/1223 [=======>......................] - ETA: 0s - loss: 0.1236 - acc: 0.9743
 450/1223 [==========>...................] - ETA: 0s - loss: 0.1289 - acc: 0.9689
 550/1223 [============>.................] - ETA: 0s - loss: 0.1382 - acc: 0.9636
 650/1223 [==============>...............] - ETA: 0s - loss: 0.1325 - acc: 0.9646
 750/1223 [=================>............] - ETA: 0s - loss: 0.1313 - acc: 0.9613
 850/1223 [===================>..........] - ETA: 0s - loss: 0.1273 - acc: 0.9612
 950/1223 [======================>.......] - ETA: 0s - loss: 0.1228 - acc: 0.9621
1050/1223 [========================>.....] - ETA: 0s - loss: 0.1222 - acc: 0.9619
1150/1223 [===========================>..] - ETA: 0s - loss: 0.1169 - acc: 0.9643
1223/1223 [==============================] - 1s 619us/step - loss: 0.1124 - acc: 0.9665 - val_loss: 0.2947 - val_acc: 0.8889

Epoch 00003: val_acc did not improve from 0.88889
Epoch 4/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0882 - acc: 0.9800
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0574 - acc: 0.9867
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0481 - acc: 0.9880
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0457 - acc: 0.9886
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0412 - acc: 0.9911
 550/1223 [============>.................] - ETA: 0s - loss: 0.0473 - acc: 0.9909
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0507 - acc: 0.9892
 750/1223 [=================>............] - ETA: 0s - loss: 0.0498 - acc: 0.9907
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0479 - acc: 0.9906
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0469 - acc: 0.9905
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0445 - acc: 0.9914
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0435 - acc: 0.9913
1223/1223 [==============================] - 1s 619us/step - loss: 0.0439 - acc: 0.9910 - val_loss: 0.3618 - val_acc: 0.8889

Epoch 00004: val_acc did not improve from 0.88889
Epoch 5/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0259 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0238 - acc: 0.9960
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0210 - acc: 0.9971
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0216 - acc: 0.9978
 550/1223 [============>.................] - ETA: 0s - loss: 0.0208 - acc: 0.9982
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0200 - acc: 0.9985
 750/1223 [=================>............] - ETA: 0s - loss: 0.0184 - acc: 0.9987
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0172 - acc: 0.9988
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0171 - acc: 0.9989
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0165 - acc: 0.9990
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0157 - acc: 0.9991
1223/1223 [==============================] - 1s 613us/step - loss: 0.0157 - acc: 0.9992 - val_loss: 0.3317 - val_acc: 0.8889

Epoch 00005: val_acc did not improve from 0.88889
Epoch 6/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0095 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0072 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0083 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0109 - acc: 0.9971
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0116 - acc: 0.9978
 550/1223 [============>.................] - ETA: 0s - loss: 0.0112 - acc: 0.9982
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0107 - acc: 0.9985
 750/1223 [=================>............] - ETA: 0s - loss: 0.0106 - acc: 0.9987
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0107 - acc: 0.9988
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0104 - acc: 0.9989
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0110 - acc: 0.9981
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0104 - acc: 0.9983
1223/1223 [==============================] - 1s 615us/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.3218 - val_acc: 0.8889

Epoch 00006: val_acc did not improve from 0.88889
Epoch 7/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0072 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0071 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0067 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0067 - acc: 1.0000
1223/1223 [==============================] - 1s 615us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.8889

Epoch 00007: val_acc did not improve from 0.88889

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 8/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0060 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0061 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0058 - acc: 1.0000
1223/1223 [==============================] - 1s 617us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.8889

Epoch 00008: val_acc did not improve from 0.88889
Epoch 9/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1223/1223 [==============================] - 1s 619us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 0.8889

Epoch 00009: val_acc did not improve from 0.88889
Epoch 10/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0039 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 1.0000
1223/1223 [==============================] - 1s 619us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2215 - val_acc: 0.8889

Epoch 00010: val_acc did not improve from 0.88889
Epoch 11/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1223/1223 [==============================] - 1s 617us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2128 - val_acc: 0.8889

Epoch 00011: val_acc did not improve from 0.88889
Epoch 12/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0030 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0036 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0039 - acc: 1.0000
1223/1223 [==============================] - 1s 618us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.8889

Epoch 00012: val_acc did not improve from 0.88889

Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 13/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1223/1223 [==============================] - 1s 616us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.8889

Epoch 00013: val_acc did not improve from 0.88889
Epoch 14/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0030 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0029 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0027 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 1.0000
1223/1223 [==============================] - 1s 613us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.8889

Epoch 00014: val_acc did not improve from 0.88889
Epoch 15/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0038 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0036 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 1.0000
1223/1223 [==============================] - 1s 613us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.8889

Epoch 00015: val_acc did not improve from 0.88889
Epoch 16/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1223/1223 [==============================] - 1s 615us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2418 - val_acc: 0.8889

Epoch 00016: val_acc did not improve from 0.88889
Epoch 17/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0032 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0034 - acc: 1.0000
1223/1223 [==============================] - 1s 614us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2385 - val_acc: 0.8889

Epoch 00017: val_acc did not improve from 0.88889

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 18/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0030 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1223/1223 [==============================] - 1s 613us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2382 - val_acc: 0.8889

Epoch 00018: val_acc did not improve from 0.88889
Epoch 19/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1223/1223 [==============================] - 1s 616us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2379 - val_acc: 0.8889

Epoch 00019: val_acc did not improve from 0.88889
Epoch 20/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0030 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0027 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0028 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0030 - acc: 1.0000
1223/1223 [==============================] - 1s 615us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2378 - val_acc: 0.8889

Epoch 00020: val_acc did not improve from 0.88889
Epoch 21/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0018 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0038 - acc: 1.0000
1223/1223 [==============================] - 1s 612us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2391 - val_acc: 0.8889

Epoch 00021: val_acc did not improve from 0.88889
Epoch 22/200

  50/1223 [>.............................] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 150/1223 [==>...........................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 250/1223 [=====>........................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 350/1223 [=======>......................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 450/1223 [==========>...................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 550/1223 [============>.................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 650/1223 [==============>...............] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 750/1223 [=================>............] - ETA: 0s - loss: 0.0031 - acc: 1.0000
 850/1223 [===================>..........] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 950/1223 [======================>.......] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1050/1223 [========================>.....] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1150/1223 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 1.0000
1223/1223 [==============================] - 1s 613us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2395 - val_acc: 0.8889
Using TensorFlow backend.

Epoch 00022: val_acc did not improve from 0.88889
Epoch 00022: early stopping
>> TEST ...
Test Accuracy: 0.8888888888888888
[[0 0 0]
 [1 5 0]
 [0 0 3]]
> training sub-category <location> ..
>> sub-category: loc
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  country.txt (155, 9600) (155,) 155
TRAIN ::  state.txt (66, 9600) (66,) 66
TRAIN ::  city.txt (129, 9600) (129,) 129
TEST ::  city.txt (18, 9600) (18,) 18
TRAIN ::  mount.txt (21, 9600) (21,) 21
TRAIN ::  other.txt (464, 9600) (464,) 464
x_train: (835, 9600)  - y_train: (835,) - train_questions: 835
x_test: (18, 9600)  - y_test: (18,) - test_questions: 18
x_train: (835, 32, 300, 1)  - y_train: (835, 5) - train_questions: 835
x_test: (18, 32, 300, 1)  - y_test: (18, 5) - test_questions: 18
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 5)            325         dropout_2[0][0]                  
==================================================================================================
Total params: 2,366,709
Trainable params: 2,366,709
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 835 samples, validate on 18 samples
Epoch 1/200

 50/835 [>.............................] - ETA: 32s - loss: 1.6087 - acc: 0.2200
150/835 [====>.........................] - ETA: 9s - loss: 1.3283 - acc: 0.4800 
250/835 [=======>......................] - ETA: 5s - loss: 1.2386 - acc: 0.5400
350/835 [===========>..................] - ETA: 3s - loss: 1.1932 - acc: 0.5543
450/835 [===============>..............] - ETA: 2s - loss: 1.1641 - acc: 0.5578
550/835 [==================>...........] - ETA: 1s - loss: 1.1053 - acc: 0.5873
650/835 [======================>.......] - ETA: 0s - loss: 1.0721 - acc: 0.6015
750/835 [=========================>....] - ETA: 0s - loss: 1.0254 - acc: 0.6227
835/835 [==============================] - 3s 3ms/step - loss: 0.9715 - acc: 0.6467 - val_loss: 1.3028 - val_acc: 0.5556

Epoch 00001: val_acc improved from -inf to 0.55556, saving model to word2vec_loc_model.h5
Epoch 2/200

 50/835 [>.............................] - ETA: 0s - loss: 0.4127 - acc: 0.8800
150/835 [====>.........................] - ETA: 0s - loss: 0.4322 - acc: 0.8800
250/835 [=======>......................] - ETA: 0s - loss: 0.3695 - acc: 0.9040
350/835 [===========>..................] - ETA: 0s - loss: 0.3354 - acc: 0.9171
450/835 [===============>..............] - ETA: 0s - loss: 0.3474 - acc: 0.9111
550/835 [==================>...........] - ETA: 0s - loss: 0.3114 - acc: 0.9255
650/835 [======================>.......] - ETA: 0s - loss: 0.2983 - acc: 0.9292
750/835 [=========================>....] - ETA: 0s - loss: 0.3002 - acc: 0.9267
835/835 [==============================] - 1s 632us/step - loss: 0.2910 - acc: 0.9269 - val_loss: 0.6721 - val_acc: 0.8333

Epoch 00002: val_acc improved from 0.55556 to 0.83333, saving model to word2vec_loc_model.h5
Epoch 3/200

 50/835 [>.............................] - ETA: 0s - loss: 0.2866 - acc: 0.9400
150/835 [====>.........................] - ETA: 0s - loss: 0.1740 - acc: 0.9600
250/835 [=======>......................] - ETA: 0s - loss: 0.1355 - acc: 0.9720
350/835 [===========>..................] - ETA: 0s - loss: 0.1230 - acc: 0.9771
450/835 [===============>..............] - ETA: 0s - loss: 0.1226 - acc: 0.9733
550/835 [==================>...........] - ETA: 0s - loss: 0.1255 - acc: 0.9691
650/835 [======================>.......] - ETA: 0s - loss: 0.1271 - acc: 0.9662
750/835 [=========================>....] - ETA: 0s - loss: 0.1185 - acc: 0.9680
835/835 [==============================] - 1s 628us/step - loss: 0.1147 - acc: 0.9689 - val_loss: 0.4960 - val_acc: 0.9444

Epoch 00003: val_acc improved from 0.83333 to 0.94444, saving model to word2vec_loc_model.h5
Epoch 4/200

 50/835 [>.............................] - ETA: 0s - loss: 0.1363 - acc: 0.9800
150/835 [====>.........................] - ETA: 0s - loss: 0.1126 - acc: 0.9800
250/835 [=======>......................] - ETA: 0s - loss: 0.0817 - acc: 0.9880
350/835 [===========>..................] - ETA: 0s - loss: 0.0812 - acc: 0.9829
450/835 [===============>..............] - ETA: 0s - loss: 0.0825 - acc: 0.9778
550/835 [==================>...........] - ETA: 0s - loss: 0.0737 - acc: 0.9818
650/835 [======================>.......] - ETA: 0s - loss: 0.0692 - acc: 0.9831
750/835 [=========================>....] - ETA: 0s - loss: 0.0639 - acc: 0.9853
835/835 [==============================] - 1s 626us/step - loss: 0.0598 - acc: 0.9868 - val_loss: 0.9122 - val_acc: 0.8333

Epoch 00004: val_acc did not improve from 0.94444
Epoch 5/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0190 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0457 - acc: 0.9920
350/835 [===========>..................] - ETA: 0s - loss: 0.0387 - acc: 0.9943
450/835 [===============>..............] - ETA: 0s - loss: 0.0365 - acc: 0.9956
550/835 [==================>...........] - ETA: 0s - loss: 0.0341 - acc: 0.9964
650/835 [======================>.......] - ETA: 0s - loss: 0.0367 - acc: 0.9954
750/835 [=========================>....] - ETA: 0s - loss: 0.0347 - acc: 0.9960
835/835 [==============================] - 1s 624us/step - loss: 0.0347 - acc: 0.9952 - val_loss: 0.8530 - val_acc: 0.8333

Epoch 00005: val_acc did not improve from 0.94444
Epoch 6/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0848 - acc: 0.9800
150/835 [====>.........................] - ETA: 0s - loss: 0.0404 - acc: 0.9867
250/835 [=======>......................] - ETA: 0s - loss: 0.0288 - acc: 0.9920
350/835 [===========>..................] - ETA: 0s - loss: 0.0251 - acc: 0.9943
450/835 [===============>..............] - ETA: 0s - loss: 0.0233 - acc: 0.9956
550/835 [==================>...........] - ETA: 0s - loss: 0.0285 - acc: 0.9945
650/835 [======================>.......] - ETA: 0s - loss: 0.0273 - acc: 0.9954
750/835 [=========================>....] - ETA: 0s - loss: 0.0272 - acc: 0.9947
835/835 [==============================] - 1s 626us/step - loss: 0.0262 - acc: 0.9952 - val_loss: 0.7620 - val_acc: 0.8333

Epoch 00006: val_acc did not improve from 0.94444
Epoch 7/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0166 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0121 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0126 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0291 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0247 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0230 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0223 - acc: 0.9969
750/835 [=========================>....] - ETA: 0s - loss: 0.0215 - acc: 0.9973
835/835 [==============================] - 1s 623us/step - loss: 0.0208 - acc: 0.9976 - val_loss: 0.9802 - val_acc: 0.8333

Epoch 00007: val_acc did not improve from 0.94444
Epoch 8/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0093 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0444 - acc: 0.9933
250/835 [=======>......................] - ETA: 0s - loss: 0.0297 - acc: 0.9960
350/835 [===========>..................] - ETA: 0s - loss: 0.0232 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0209 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0183 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0170 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0171 - acc: 0.9973
835/835 [==============================] - 1s 626us/step - loss: 0.0163 - acc: 0.9976 - val_loss: 1.1437 - val_acc: 0.8333

Epoch 00008: val_acc did not improve from 0.94444

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 9/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0101 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0121 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0118 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0182 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0166 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0155 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0139 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0128 - acc: 0.9987
835/835 [==============================] - 1s 625us/step - loss: 0.0141 - acc: 0.9976 - val_loss: 1.1188 - val_acc: 0.8333

Epoch 00009: val_acc did not improve from 0.94444
Epoch 10/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0071 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0072 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0070 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0091 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0102 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0099 - acc: 0.9987
835/835 [==============================] - 1s 624us/step - loss: 0.0097 - acc: 0.9988 - val_loss: 1.0792 - val_acc: 0.8333

Epoch 00010: val_acc did not improve from 0.94444
Epoch 11/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0079 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0069 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0070 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0070 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0127 - acc: 0.9987
835/835 [==============================] - 1s 624us/step - loss: 0.0119 - acc: 0.9988 - val_loss: 1.0883 - val_acc: 0.8333

Epoch 00011: val_acc did not improve from 0.94444
Epoch 12/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0088 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0075 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0079 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0082 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0074 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0070 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0084 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0091 - acc: 0.9987
835/835 [==============================] - 1s 627us/step - loss: 0.0089 - acc: 0.9988 - val_loss: 1.1433 - val_acc: 0.8333

Epoch 00012: val_acc did not improve from 0.94444
Epoch 13/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0085 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0080 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0093 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0088 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0079 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0080 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0081 - acc: 1.0000
835/835 [==============================] - 1s 626us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.0986 - val_acc: 0.8333

Epoch 00013: val_acc did not improve from 0.94444

Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 14/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0225 - acc: 0.9933
250/835 [=======>......................] - ETA: 0s - loss: 0.0162 - acc: 0.9960
350/835 [===========>..................] - ETA: 0s - loss: 0.0145 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0126 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0113 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0107 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0101 - acc: 0.9987
835/835 [==============================] - 1s 623us/step - loss: 0.0097 - acc: 0.9988 - val_loss: 1.0844 - val_acc: 0.8333

Epoch 00014: val_acc did not improve from 0.94444
Epoch 15/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0061 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0059 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0061 - acc: 1.0000
835/835 [==============================] - 1s 620us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.8333

Epoch 00015: val_acc did not improve from 0.94444
Epoch 16/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0054 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0065 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0093 - acc: 0.9987
835/835 [==============================] - 1s 624us/step - loss: 0.0089 - acc: 0.9988 - val_loss: 1.0820 - val_acc: 0.8333

Epoch 00016: val_acc did not improve from 0.94444
Epoch 17/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0067 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0129 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0118 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0108 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0101 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0095 - acc: 1.0000
835/835 [==============================] - 1s 626us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.0606 - val_acc: 0.8333

Epoch 00017: val_acc did not improve from 0.94444
Epoch 18/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0089 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0087 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0087 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0081 - acc: 1.0000
835/835 [==============================] - 1s 620us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.0679 - val_acc: 0.8333

Epoch 00018: val_acc did not improve from 0.94444

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 19/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0167 - acc: 0.9933
250/835 [=======>......................] - ETA: 0s - loss: 0.0132 - acc: 0.9960
350/835 [===========>..................] - ETA: 0s - loss: 0.0114 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0098 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0089 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0087 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0083 - acc: 0.9987
835/835 [==============================] - 1s 623us/step - loss: 0.0095 - acc: 0.9976 - val_loss: 1.0680 - val_acc: 0.8333

Epoch 00019: val_acc did not improve from 0.94444
Epoch 20/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0031 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0071 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0111 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0100 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0095 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0088 - acc: 0.9987
835/835 [==============================] - 1s 626us/step - loss: 0.0087 - acc: 0.9988 - val_loss: 1.0734 - val_acc: 0.8333

Epoch 00020: val_acc did not improve from 0.94444
Epoch 21/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0211 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0112 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0087 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0081 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0077 - acc: 1.0000
550/835 [==================>...........] - ETA: 0s - loss: 0.0075 - acc: 1.0000
650/835 [======================>.......] - ETA: 0s - loss: 0.0074 - acc: 1.0000
750/835 [=========================>....] - ETA: 0s - loss: 0.0077 - acc: 1.0000
835/835 [==============================] - 1s 622us/step - loss: 0.0092 - acc: 0.9988 - val_loss: 1.0739 - val_acc: 0.8333

Epoch 00021: val_acc did not improve from 0.94444
Epoch 22/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0370 - acc: 0.9800
150/835 [====>.........................] - ETA: 0s - loss: 0.0177 - acc: 0.9933
250/835 [=======>......................] - ETA: 0s - loss: 0.0144 - acc: 0.9960
350/835 [===========>..................] - ETA: 0s - loss: 0.0122 - acc: 0.9971
450/835 [===============>..............] - ETA: 0s - loss: 0.0117 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0104 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0109 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0099 - acc: 0.9987
835/835 [==============================] - 1s 621us/step - loss: 0.0101 - acc: 0.9988 - val_loss: 1.0687 - val_acc: 0.8333

Epoch 00022: val_acc did not improve from 0.94444
Epoch 23/200

 50/835 [>.............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
150/835 [====>.........................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
250/835 [=======>......................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
350/835 [===========>..................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
450/835 [===============>..............] - ETA: 0s - loss: 0.0082 - acc: 0.9978
550/835 [==================>...........] - ETA: 0s - loss: 0.0077 - acc: 0.9982
650/835 [======================>.......] - ETA: 0s - loss: 0.0075 - acc: 0.9985
750/835 [=========================>....] - ETA: 0s - loss: 0.0074 - acc: 0.9987
835/835 [==============================] - 1s 625us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 1.0658 - val_acc: 0.8333
Using TensorFlow backend.

Epoch 00023: val_acc did not improve from 0.94444
Epoch 00023: early stopping
>> TEST ...
Test Accuracy: 0.9444444444444444
[[17  1]
 [ 0  0]]
> training sub-category <numeric> ..
>> sub-category: num
>> loading GoogleNews-vectors-negative300.bin ...
>> making dataset / building model...
TRAIN ::  period.txt (75, 9600) (75,) 75
TEST ::  period.txt (8, 9600) (8,) 8
TRAIN ::  dist.txt (34, 9600) (34,) 34
TEST ::  dist.txt (16, 9600) (16,) 16
TRAIN ::  date.txt (218, 9600) (218,) 218
TEST ::  date.txt (47, 9600) (47,) 47
TRAIN ::  code.txt (9, 9600) (9,) 9
TRAIN ::  speed.txt (9, 9600) (9,) 9
TEST ::  speed.txt (6, 9600) (6,) 6
TRAIN ::  count.txt (363, 9600) (363,) 363
TEST ::  count.txt (9, 9600) (9,) 9
TRAIN ::  temp.txt (8, 9600) (8,) 8
TEST ::  temp.txt (5, 9600) (5,) 5
TRAIN ::  perc.txt (27, 9600) (27,) 27
TEST ::  perc.txt (3, 9600) (3,) 3
TRAIN ::  weight.txt (11, 9600) (11,) 11
TEST ::  weight.txt (4, 9600) (4,) 4
TRAIN ::  ord.txt (6, 9600) (6,) 6
TRAIN ::  money.txt (71, 9600) (71,) 71
TEST ::  money.txt (3, 9600) (3,) 3
TRAIN ::  other.txt (52, 9600) (52,) 52
TEST ::  other.txt (12, 9600) (12,) 12
TRAIN ::  volsize.txt (13, 9600) (13,) 13
x_train: (896, 9600)  - y_train: (896,) - train_questions: 896
x_test: (113, 9600)  - y_test: (113,) - test_questions: 113
x_train: (896, 32, 300, 1)  - y_train: (896, 13) - train_questions: 896
x_test: (113, 32, 300, 1)  - y_test: (113, 13) - test_questions: 113
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 300, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 31, 1, 500)   300500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 1, 500)   450500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 29, 1, 500)   600500      input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 1, 500)   750500      input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 500)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1, 1, 2000)   0           max_pooling2d_1[0][0]            
                                                                 max_pooling2d_2[0][0]            
                                                                 max_pooling2d_3[0][0]            
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2000)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          256128      flatten_1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 13)           845         dropout_2[0][0]                  
==================================================================================================
Total params: 2,367,229
Trainable params: 2,367,229
Non-trainable params: 0
__________________________________________________________________________________________________
>> TRAINING ...
Train on 896 samples, validate on 113 samples
Epoch 1/200

 50/896 [>.............................] - ETA: 33s - loss: 2.5612 - acc: 0.0600
150/896 [====>.........................] - ETA: 10s - loss: 2.2618 - acc: 0.2667
250/896 [=======>......................] - ETA: 5s - loss: 2.0382 - acc: 0.3440 
350/896 [==========>...................] - ETA: 3s - loss: 1.9724 - acc: 0.3886
450/896 [==============>...............] - ETA: 2s - loss: 1.8521 - acc: 0.4378
550/896 [=================>............] - ETA: 1s - loss: 1.7424 - acc: 0.4764
650/896 [====================>.........] - ETA: 0s - loss: 1.6631 - acc: 0.5031
750/896 [========================>.....] - ETA: 0s - loss: 1.6400 - acc: 0.5160
850/896 [===========================>..] - ETA: 0s - loss: 1.5770 - acc: 0.5365
896/896 [==============================] - 3s 3ms/step - loss: 1.5600 - acc: 0.5435 - val_loss: 1.3571 - val_acc: 0.6283

Epoch 00001: val_acc improved from -inf to 0.62832, saving model to word2vec_num_model.h5
Epoch 2/200

 50/896 [>.............................] - ETA: 0s - loss: 1.1163 - acc: 0.7000
150/896 [====>.........................] - ETA: 0s - loss: 0.9619 - acc: 0.7600
250/896 [=======>......................] - ETA: 0s - loss: 0.9676 - acc: 0.7520
350/896 [==========>...................] - ETA: 0s - loss: 0.9222 - acc: 0.7600
450/896 [==============>...............] - ETA: 0s - loss: 0.9392 - acc: 0.7378
550/896 [=================>............] - ETA: 0s - loss: 0.8881 - acc: 0.7527
650/896 [====================>.........] - ETA: 0s - loss: 0.8555 - acc: 0.7662
750/896 [========================>.....] - ETA: 0s - loss: 0.8202 - acc: 0.7760
850/896 [===========================>..] - ETA: 0s - loss: 0.7864 - acc: 0.7871
896/896 [==============================] - 1s 639us/step - loss: 0.7779 - acc: 0.7891 - val_loss: 0.9330 - val_acc: 0.7080

Epoch 00002: val_acc improved from 0.62832 to 0.70796, saving model to word2vec_num_model.h5
Epoch 3/200

 50/896 [>.............................] - ETA: 0s - loss: 0.4257 - acc: 0.8800
150/896 [====>.........................] - ETA: 0s - loss: 0.4903 - acc: 0.8800
250/896 [=======>......................] - ETA: 0s - loss: 0.5089 - acc: 0.8680
350/896 [==========>...................] - ETA: 0s - loss: 0.4861 - acc: 0.8800
450/896 [==============>...............] - ETA: 0s - loss: 0.4736 - acc: 0.8800
550/896 [=================>............] - ETA: 0s - loss: 0.4476 - acc: 0.8945
650/896 [====================>.........] - ETA: 0s - loss: 0.4312 - acc: 0.9015
750/896 [========================>.....] - ETA: 0s - loss: 0.4104 - acc: 0.9080
850/896 [===========================>..] - ETA: 0s - loss: 0.4016 - acc: 0.9129
896/896 [==============================] - 1s 639us/step - loss: 0.3929 - acc: 0.9152 - val_loss: 0.6322 - val_acc: 0.7965

Epoch 00003: val_acc improved from 0.70796 to 0.79646, saving model to word2vec_num_model.h5
Epoch 4/200

 50/896 [>.............................] - ETA: 0s - loss: 0.2093 - acc: 0.9800
150/896 [====>.........................] - ETA: 0s - loss: 0.1972 - acc: 0.9800
250/896 [=======>......................] - ETA: 0s - loss: 0.2040 - acc: 0.9680
350/896 [==========>...................] - ETA: 0s - loss: 0.2261 - acc: 0.9629
450/896 [==============>...............] - ETA: 0s - loss: 0.2249 - acc: 0.9622
550/896 [=================>............] - ETA: 0s - loss: 0.2177 - acc: 0.9636
650/896 [====================>.........] - ETA: 0s - loss: 0.2143 - acc: 0.9646
750/896 [========================>.....] - ETA: 0s - loss: 0.2116 - acc: 0.9680
850/896 [===========================>..] - ETA: 0s - loss: 0.2192 - acc: 0.9671
896/896 [==============================] - 1s 640us/step - loss: 0.2157 - acc: 0.9688 - val_loss: 0.4778 - val_acc: 0.8673

Epoch 00004: val_acc improved from 0.79646 to 0.86726, saving model to word2vec_num_model.h5
Epoch 5/200

 50/896 [>.............................] - ETA: 0s - loss: 0.1330 - acc: 0.9800
150/896 [====>.........................] - ETA: 0s - loss: 0.1288 - acc: 0.9867
250/896 [=======>......................] - ETA: 0s - loss: 0.1337 - acc: 0.9880
350/896 [==========>...................] - ETA: 0s - loss: 0.1342 - acc: 0.9857
450/896 [==============>...............] - ETA: 0s - loss: 0.1437 - acc: 0.9844
550/896 [=================>............] - ETA: 0s - loss: 0.1409 - acc: 0.9818
650/896 [====================>.........] - ETA: 0s - loss: 0.1381 - acc: 0.9815
750/896 [========================>.....] - ETA: 0s - loss: 0.1332 - acc: 0.9840
850/896 [===========================>..] - ETA: 0s - loss: 0.1282 - acc: 0.9859
896/896 [==============================] - 1s 641us/step - loss: 0.1272 - acc: 0.9866 - val_loss: 0.3815 - val_acc: 0.8850

Epoch 00005: val_acc improved from 0.86726 to 0.88496, saving model to word2vec_num_model.h5
Epoch 6/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0742 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.1150 - acc: 0.9933
250/896 [=======>......................] - ETA: 0s - loss: 0.0999 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.1011 - acc: 0.9943
450/896 [==============>...............] - ETA: 0s - loss: 0.0992 - acc: 0.9911
550/896 [=================>............] - ETA: 0s - loss: 0.0960 - acc: 0.9927
650/896 [====================>.........] - ETA: 0s - loss: 0.0914 - acc: 0.9938
750/896 [========================>.....] - ETA: 0s - loss: 0.0891 - acc: 0.9933
850/896 [===========================>..] - ETA: 0s - loss: 0.0955 - acc: 0.9929
896/896 [==============================] - 1s 642us/step - loss: 0.0935 - acc: 0.9933 - val_loss: 0.4038 - val_acc: 0.8761

Epoch 00006: val_acc did not improve from 0.88496
Epoch 7/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0971 - acc: 0.9800
150/896 [====>.........................] - ETA: 0s - loss: 0.0804 - acc: 0.9933
250/896 [=======>......................] - ETA: 0s - loss: 0.0679 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0869 - acc: 0.9943
450/896 [==============>...............] - ETA: 0s - loss: 0.0805 - acc: 0.9956
550/896 [=================>............] - ETA: 0s - loss: 0.0776 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0742 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0785 - acc: 0.9960
850/896 [===========================>..] - ETA: 0s - loss: 0.0756 - acc: 0.9965
896/896 [==============================] - 1s 640us/step - loss: 0.0753 - acc: 0.9967 - val_loss: 0.3537 - val_acc: 0.8938

Epoch 00007: val_acc improved from 0.88496 to 0.89381, saving model to word2vec_num_model.h5
Epoch 8/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0498 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0444 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0488 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0500 - acc: 0.9971
450/896 [==============>...............] - ETA: 0s - loss: 0.0514 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0486 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0559 - acc: 0.9954
750/896 [========================>.....] - ETA: 0s - loss: 0.0556 - acc: 0.9947
850/896 [===========================>..] - ETA: 0s - loss: 0.0553 - acc: 0.9953
896/896 [==============================] - 1s 642us/step - loss: 0.0547 - acc: 0.9955 - val_loss: 0.3346 - val_acc: 0.8850

Epoch 00008: val_acc did not improve from 0.89381
Epoch 9/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0461 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0672 - acc: 0.9933
250/896 [=======>......................] - ETA: 0s - loss: 0.0752 - acc: 0.9920
350/896 [==========>...................] - ETA: 0s - loss: 0.0660 - acc: 0.9943
450/896 [==============>...............] - ETA: 0s - loss: 0.0609 - acc: 0.9956
550/896 [=================>............] - ETA: 0s - loss: 0.0553 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0529 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0493 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9965
896/896 [==============================] - 1s 640us/step - loss: 0.0503 - acc: 0.9967 - val_loss: 0.3529 - val_acc: 0.8850

Epoch 00009: val_acc did not improve from 0.89381
Epoch 10/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0334 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0368 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0366 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0344 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0357 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0470 - acc: 0.9945
650/896 [====================>.........] - ETA: 0s - loss: 0.0452 - acc: 0.9954
750/896 [========================>.....] - ETA: 0s - loss: 0.0419 - acc: 0.9960
850/896 [===========================>..] - ETA: 0s - loss: 0.0447 - acc: 0.9953
896/896 [==============================] - 1s 641us/step - loss: 0.0439 - acc: 0.9955 - val_loss: 0.3520 - val_acc: 0.8938

Epoch 00010: val_acc did not improve from 0.89381
Epoch 11/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0292 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0267 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0281 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0270 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0316 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0444 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0422 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0404 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9976
896/896 [==============================] - 1s 640us/step - loss: 0.0388 - acc: 0.9978 - val_loss: 0.3790 - val_acc: 0.8850

Epoch 00011: val_acc did not improve from 0.89381
Epoch 12/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0322 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0315 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0281 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0306 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0289 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0322 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0309 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0302 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0302 - acc: 0.9988
896/896 [==============================] - 1s 641us/step - loss: 0.0310 - acc: 0.9989 - val_loss: 0.3707 - val_acc: 0.8584

Epoch 00012: val_acc did not improve from 0.89381

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 13/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0318 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0289 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0281 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0310 - acc: 0.9971
450/896 [==============>...............] - ETA: 0s - loss: 0.0294 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0307 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0295 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0304 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0292 - acc: 0.9976
896/896 [==============================] - 1s 640us/step - loss: 0.0294 - acc: 0.9978 - val_loss: 0.3568 - val_acc: 0.8938

Epoch 00013: val_acc did not improve from 0.89381
Epoch 14/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0283 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0271 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0245 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0238 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0234 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0225 - acc: 1.0000
750/896 [========================>.....] - ETA: 0s - loss: 0.0225 - acc: 1.0000
850/896 [===========================>..] - ETA: 0s - loss: 0.0233 - acc: 0.9988
896/896 [==============================] - 1s 640us/step - loss: 0.0235 - acc: 0.9989 - val_loss: 0.3474 - val_acc: 0.8938

Epoch 00014: val_acc did not improve from 0.89381
Epoch 15/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0237 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0195 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0200 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0202 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0232 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0238 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0245 - acc: 0.9988
896/896 [==============================] - 1s 640us/step - loss: 0.0245 - acc: 0.9989 - val_loss: 0.3476 - val_acc: 0.8938

Epoch 00015: val_acc did not improve from 0.89381
Epoch 16/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0340 - acc: 0.9933
250/896 [=======>......................] - ETA: 0s - loss: 0.0255 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0223 - acc: 0.9971
450/896 [==============>...............] - ETA: 0s - loss: 0.0222 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0278 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0273 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0259 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0248 - acc: 0.9976
896/896 [==============================] - 1s 638us/step - loss: 0.0256 - acc: 0.9978 - val_loss: 0.3538 - val_acc: 0.8850

Epoch 00016: val_acc did not improve from 0.89381
Epoch 17/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0439 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0295 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0325 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0292 - acc: 0.9971
450/896 [==============>...............] - ETA: 0s - loss: 0.0259 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0286 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0293 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0270 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0275 - acc: 0.9965
896/896 [==============================] - 1s 641us/step - loss: 0.0273 - acc: 0.9967 - val_loss: 0.3493 - val_acc: 0.8850

Epoch 00017: val_acc did not improve from 0.89381

Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 18/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0128 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0198 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0197 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0202 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0210 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0214 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0217 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0256 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0243 - acc: 0.9976
896/896 [==============================] - 1s 638us/step - loss: 0.0251 - acc: 0.9978 - val_loss: 0.3477 - val_acc: 0.8850

Epoch 00018: val_acc did not improve from 0.89381
Epoch 19/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0269 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0218 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0227 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0230 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0214 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0206 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0216 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0220 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9988
896/896 [==============================] - 1s 641us/step - loss: 0.0220 - acc: 0.9989 - val_loss: 0.3470 - val_acc: 0.8850

Epoch 00019: val_acc did not improve from 0.89381
Epoch 20/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0094 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0156 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0184 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0175 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0185 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0239 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0234 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0228 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0244 - acc: 0.9976
896/896 [==============================] - 1s 640us/step - loss: 0.0241 - acc: 0.9978 - val_loss: 0.3444 - val_acc: 0.8850

Epoch 00020: val_acc did not improve from 0.89381
Epoch 21/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0169 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0165 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0220 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0261 - acc: 0.9943
450/896 [==============>...............] - ETA: 0s - loss: 0.0252 - acc: 0.9956
550/896 [=================>............] - ETA: 0s - loss: 0.0238 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0233 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0218 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0214 - acc: 0.9976
896/896 [==============================] - 1s 638us/step - loss: 0.0210 - acc: 0.9978 - val_loss: 0.3431 - val_acc: 0.8850

Epoch 00021: val_acc did not improve from 0.89381
Epoch 22/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0095 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0166 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0167 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0167 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0188 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0176 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0185 - acc: 1.0000
750/896 [========================>.....] - ETA: 0s - loss: 0.0202 - acc: 1.0000
850/896 [===========================>..] - ETA: 0s - loss: 0.0206 - acc: 1.0000
896/896 [==============================] - 1s 639us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.3418 - val_acc: 0.8850

Epoch 00022: val_acc did not improve from 0.89381

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 23/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0119 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0156 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0178 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0171 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0179 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0174 - acc: 1.0000
750/896 [========================>.....] - ETA: 0s - loss: 0.0169 - acc: 1.0000
850/896 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 1.0000
896/896 [==============================] - 1s 641us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3417 - val_acc: 0.8850

Epoch 00023: val_acc did not improve from 0.89381
Epoch 24/200

 50/896 [>.............................] - ETA: 0s - loss: 0.1272 - acc: 0.9800
150/896 [====>.........................] - ETA: 0s - loss: 0.0547 - acc: 0.9933
250/896 [=======>......................] - ETA: 0s - loss: 0.0426 - acc: 0.9960
350/896 [==========>...................] - ETA: 0s - loss: 0.0372 - acc: 0.9971
450/896 [==============>...............] - ETA: 0s - loss: 0.0349 - acc: 0.9956
550/896 [=================>............] - ETA: 0s - loss: 0.0321 - acc: 0.9964
650/896 [====================>.........] - ETA: 0s - loss: 0.0304 - acc: 0.9969
750/896 [========================>.....] - ETA: 0s - loss: 0.0286 - acc: 0.9973
850/896 [===========================>..] - ETA: 0s - loss: 0.0268 - acc: 0.9976
896/896 [==============================] - 1s 638us/step - loss: 0.0265 - acc: 0.9978 - val_loss: 0.3423 - val_acc: 0.8850

Epoch 00024: val_acc did not improve from 0.89381
Epoch 25/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0098 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0203 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0238 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0204 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0258 - acc: 0.9978
550/896 [=================>............] - ETA: 0s - loss: 0.0243 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0229 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0221 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0213 - acc: 0.9988
896/896 [==============================] - 1s 638us/step - loss: 0.0212 - acc: 0.9989 - val_loss: 0.3422 - val_acc: 0.8850

Epoch 00025: val_acc did not improve from 0.89381
Epoch 26/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0166 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0184 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0182 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0192 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0189 - acc: 1.0000
650/896 [====================>.........] - ETA: 0s - loss: 0.0183 - acc: 1.0000
750/896 [========================>.....] - ETA: 0s - loss: 0.0204 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0209 - acc: 0.9988
896/896 [==============================] - 1s 641us/step - loss: 0.0205 - acc: 0.9989 - val_loss: 0.3417 - val_acc: 0.8850

Epoch 00026: val_acc did not improve from 0.89381
Epoch 27/200

 50/896 [>.............................] - ETA: 0s - loss: 0.0094 - acc: 1.0000
150/896 [====>.........................] - ETA: 0s - loss: 0.0107 - acc: 1.0000
250/896 [=======>......................] - ETA: 0s - loss: 0.0166 - acc: 1.0000
350/896 [==========>...................] - ETA: 0s - loss: 0.0237 - acc: 1.0000
450/896 [==============>...............] - ETA: 0s - loss: 0.0223 - acc: 1.0000
550/896 [=================>............] - ETA: 0s - loss: 0.0231 - acc: 0.9982
650/896 [====================>.........] - ETA: 0s - loss: 0.0237 - acc: 0.9985
750/896 [========================>.....] - ETA: 0s - loss: 0.0242 - acc: 0.9987
850/896 [===========================>..] - ETA: 0s - loss: 0.0238 - acc: 0.9988
896/896 [==============================] - 1s 635us/step - loss: 0.0236 - acc: 0.9989 - val_loss: 0.3416 - val_acc: 0.8850
Using TensorFlow backend.

Epoch 00027: val_acc did not improve from 0.89381
Epoch 00027: early stopping
>> TEST ...
Test Accuracy: 0.8938053097345132
[[ 8  0  0  0  0  0  0  0  0  0  0]
 [ 0 12  0  0  0  0  0  0  0  3  1]
 [ 0  0 47  0  0  0  0  0  0  0  0]
 [ 1  0  0  5  0  0  0  0  0  0  0]
 [ 0  0  0  0  9  0  0  0  0  0  0]
 [ 1  0  0  0  0  4  0  0  0  0  0]
 [ 0  0  0  0  0  0  1  0  0  2  0]
 [ 0  0  0  0  0  0  0  4  0  0  0]
 [ 0  0  0  0  0  0  0  0  3  0  0]
 [ 3  0  0  0  0  0  1  0  0  8  0]
 [ 0  0  0  0  0  0  0  0  0  0  0]]
